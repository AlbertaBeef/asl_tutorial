{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2321d8cb",
   "metadata": {
    "id": "2321d8cb"
   },
   "source": [
    "<h1 style=\"font-size:30px;\">Deploying the ASL Classifier to Vitis-AI</h1>  \n",
    "\n",
    "This notebook describes how to quantize and compile a TensorFlow2 model with Vitis-AI for deployment.\n",
    "\n",
    "<img src='./images/VGG16_06_asl_fine_tuning.png' width=1000 align='center'><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f452f7",
   "metadata": {
    "id": "f5f452f7"
   },
   "source": [
    "## Table of Contents\n",
    "* [1 System Configuration](#1-System-Configuration)\n",
    "* [2 Download and Extract the Dataset](#2-Download-and-Extract-the-Dataset)\n",
    "* [3 Dataset Configuration](#3-Dataset-Configuration)\n",
    "* [4 Quantization](#4-Quantization)\n",
    "* [5 Compilation](#5-Compilation)\n",
    "* [6 Conclusion](#6-Conclusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d103ad0",
   "metadata": {
    "id": "0d103ad0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 08:22:15.575389: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 08:22:15.707838: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import zipfile\n",
    "import requests\n",
    "import glob as glob\n",
    "\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)\n",
    "from dataclasses import dataclass \n",
    "\n",
    "block_plot = False\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "SEED_VALUE = 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42883a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version :  2.10.0\n",
      "tensorflow version :  2.10.0\n",
      "opencv version :  4.6.0\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow version : \",tf.__version__)\n",
    "print(\"tensorflow version : \",keras.__version__)\n",
    "print(\"opencv version : \",cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61afbd",
   "metadata": {
    "id": "bc61afbd"
   },
   "source": [
    "## 1 System Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450b9a9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "450b9a9a",
    "outputId": "4b0ff0e3-fc7d-4689-a8f4-953b7b7fa392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "def system_config():\n",
    "    \n",
    "    # Get list of GPUs.\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(gpu_devices)\n",
    "    \n",
    "    if len(gpu_devices) > 0:\n",
    "        print('Using GPU')\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "        os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n",
    "        \n",
    "        # If there are any gpu devices, use first gpu.\n",
    "        tf.config.experimental.set_visible_devices(gpu_devices[0], 'GPU')\n",
    "        \n",
    "        # Grow the memory usage as it is needed by the process.\n",
    "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "        \n",
    "        # Enable using cudNN.\n",
    "        os.environ['TF_USE_CUDNN'] = \"true\"\n",
    "    else:\n",
    "        print('Using CPU')\n",
    "\n",
    "system_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cfe4cd",
   "metadata": {
    "id": "97cfe4cd"
   },
   "source": [
    "## 2 Download and Extract the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c6b79b",
   "metadata": {
    "id": "03c6b79b"
   },
   "outputs": [],
   "source": [
    "def download_file(url, save_name):\n",
    "    url = url\n",
    "    file = requests.get(url)\n",
    "\n",
    "    open(save_name, 'wb').write(file.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf238d22",
   "metadata": {
    "id": "bf238d22"
   },
   "outputs": [],
   "source": [
    "def unzip(zip_file=None):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file) as z:\n",
    "            z.extractall(\"./\")\n",
    "            print(\"Extracted all\")\n",
    "    except:\n",
    "        print(\"Invalid file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f0cb6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55f0cb6a",
    "outputId": "0e54ae7b-cb38-4469-9848-baa3addb5d47"
   },
   "outputs": [],
   "source": [
    "#download_file(\n",
    "#    'https://github.com/AlbertaBeef/asl_tutorial/releases/download/vitis_ai_3.0_version2/dataset_ASL_reduced.zip?dl=1', \n",
    "#    'dataset_ASL_reduced.zip'\n",
    "#)\n",
    "    \n",
    "#unzip(zip_file='dataset_ASL_reduced.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8158104",
   "metadata": {
    "id": "d8158104"
   },
   "source": [
    "## 3 Dataset and Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b8e05f",
   "metadata": {
    "id": "a9b8e05f"
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    NUM_CLASSES: int = 29\n",
    "    IMG_HEIGHT:  int = 224\n",
    "    IMG_WIDTH:   int = 224\n",
    "    CHANNELS:    int = 3\n",
    "    BATCH_SIZE:  int = 32\n",
    "    TRAINING_DATA_ROOT:   str = './dataset_ASL_reduced/training'\n",
    "    VALIDATION_DATA_ROOT:   str = './dataset_ASL_reduced/validation'\n",
    "        \n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE:     int   = 32\n",
    "    EPOCHS:         int   = 51\n",
    "    LEARNING_RATE:  float = 0.0005\n",
    "    CHECKPOINT_DIR: str   = './saved_models_asl_classifier25'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde6491",
   "metadata": {
    "id": "ddde6491"
   },
   "source": [
    "### 3.1 Prepare the Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927f1028",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "927f1028",
    "outputId": "85c82008-4818-45a3-819d-0622b7c8db1a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5800 files belonging to 29 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 08:22:18.513367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1450 files belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(directory=DatasetConfig.TRAINING_DATA_ROOT,\n",
    "                                             batch_size=TrainingConfig.BATCH_SIZE,\n",
    "                                             shuffle=True,\n",
    "                                             seed=SEED_VALUE,\n",
    "                                             label_mode='categorical',\n",
    "                                             image_size=(DatasetConfig.IMG_WIDTH, DatasetConfig.IMG_HEIGHT),\n",
    "                                            )\n",
    "\n",
    "valid_dataset = image_dataset_from_directory(directory=DatasetConfig.VALIDATION_DATA_ROOT,\n",
    "                                             batch_size=TrainingConfig.BATCH_SIZE,\n",
    "                                             shuffle=True,\n",
    "                                             seed=SEED_VALUE,\n",
    "                                             label_mode='categorical',\n",
    "                                             image_size=(DatasetConfig.IMG_WIDTH, DatasetConfig.IMG_HEIGHT),\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a43de4",
   "metadata": {},
   "source": [
    "### 3.2 Normalizing the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df240d",
   "metadata": {},
   "source": [
    "reference : https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c15aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719985ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_valid_dataset = valid_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fa33c",
   "metadata": {
    "id": "960fa33c"
   },
   "source": [
    "## 4 Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042806bf",
   "metadata": {},
   "source": [
    "**Load model**\n",
    "\n",
    "Load model for the rest of the tutorial with the `load_model` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f10bc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 16  432         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 16  64          ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 16  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 16  144        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 16  64         ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 16  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 8)  128        ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 8)  32         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 48  384         ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 48  192        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 48  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 48  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 48)  432         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 48)  192         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 48)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 16)   768         ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 16)  64          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 96)   1536        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 96)  384         ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 96)   0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 16)   1536        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 16)  64          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 16)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 96)   1536        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 96)  384         ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block_3_expand_relu (ReLU)     (None, 56, 56, 96)   0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 96)   0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 96)  864         ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 96)  384         ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 96)   0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 16)   1536        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 16)  64          ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 96)   1536        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 96)  384         ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 96)   0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 96)  864         ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 96)  384         ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 96)   0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 16)   1536        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 16)  64          ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 16)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 96)   1536        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 96)  384         ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 96)   0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 96)  864         ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 96)  384         ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 96)   0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 16)   1536        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 16)  64          ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 16)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 96)   1536        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 96)  384         ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 96)   0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 96)   0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 96)  864         ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 96)  384         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 96)   0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 32)   3072        ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 32)  128         ['block_6_project[0][0]']        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 192)  6144        ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 192)  768        ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 192)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 32)   6144        ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 32)  128         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 32)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 192)  6144        ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 192)  768        ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 192)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 32)   6144        ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 32)  128         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 32)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 192)  6144        ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 192)  768        ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 192)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 32)   6144        ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 32)  128         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 32)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 192)  6144        ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 192)  768        ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 192)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 192)  1728       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 192)  768        ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 192)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 48)   9216        ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 48)  192         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 288)  13824       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 288)  1152       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 288)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 288)  2592       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 288)  1152       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 288)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 48)   13824       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 48)  192         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 48)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 288)  13824       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 288)  1152       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 288)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 288)  2592       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 288)  1152       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 288)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 48)   13824       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 48)  192         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 48)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 288)  13824       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 288)  1152       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 288)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 288)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 288)   2592        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 288)   1152        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 288)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 80)     23040       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 80)    320         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 480)    38400       ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 480)   1920        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 480)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 480)   4320        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 480)   1920        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 480)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 80)     38400       ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 80)    320         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 80)     0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 480)    38400       ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 480)   1920        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 480)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 480)   4320        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 480)   1920        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 480)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 80)     38400       ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 80)    320         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 80)     0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 480)    38400       ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 480)   1920        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 480)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 480)   4320        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 480)   1920        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 480)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 160)    76800       ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " last_conv (Conv2D)             (None, 7, 7, 1000)   160000      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " last_bn (BatchNormalization)   (None, 7, 7, 1000)   4000        ['last_conv[0][0]']              \n",
      "                                                                                                  \n",
      " last_relu (ReLU)               (None, 7, 7, 1000)   0           ['last_bn[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pool (GlobalAve  (None, 1000)        0           ['last_relu[0][0]']              \n",
      " ragePooling2D)                                                                                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 29)           29029       ['global_average_pool[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 689,333\n",
      "Trainable params: 671,349\n",
      "Non-trainable params: 17,984\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('tf2_asl_classifier23.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4a0a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 11s 218ms/step - loss: 6.1518 - accuracy: 0.2379\n",
      "Model evaluation accuracy (validation dataset): 23.793\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation accuracy (validation dataset): {model.evaluate(valid_dataset)[1]*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc1ba273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 10s 205ms/step - loss: 0.2320 - accuracy: 0.9441\n",
      "Model evaluation accuracy (validation dataset): 94.414\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation accuracy (validation dataset): {model.evaluate(normalized_valid_dataset)[1]*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052db7",
   "metadata": {},
   "source": [
    "In order to compile the trained model for deployment on a DPU platform, we must first quantize it. Here we will use the `vitis_quantize` module to convert the floating point model into an INT8 quantized representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab4b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f0c299",
   "metadata": {},
   "source": [
    "**Quantize model**\n",
    "\n",
    "By default the `quantize_model` function converts the weights, activations and inputs into 8-bit wide numbers. We can specify different values and configurations using `weight_bit`, `activation_bit` and other parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ec24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = vitis_quantize.VitisQuantizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a4cdd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAI INFO] Update activation_bit: 8\n",
      "[VAI INFO] Update weight_bit: 8\n",
      "[VAI INFO] Quantizing without specific `target`.\n",
      "[VAI INFO] Start CrossLayerEqualization...\n",
      "10/10 [==============================] - 10s 1s/step\n",
      "[VAI INFO] CrossLayerEqualization Done.\n",
      "[VAI INFO] Start Quantize Calibration...\n",
      "46/46 [==============================] - 77s 995ms/step\n",
      "[VAI INFO] Quantize Calibration Done.\n",
      "[VAI INFO] Start Post-Quant Model Refinement...\n",
      "[VAI INFO] Start Quantize Position Ajustment...\n",
      "[VAI INFO] Quantize Position Ajustment Done.\n",
      "[VAI INFO] Post-Quant Model Refninement Done.\n",
      "[VAI INFO] Start Model Finalization...\n",
      "[VAI INFO] Model Finalization Done.\n",
      "[VAI INFO] Quantization Finished.\n"
     ]
    }
   ],
   "source": [
    "#quantized_model = quantizer.quantize_model(calib_dataset=valid_dataset, weight_bit=8, activation_bit=8)\n",
    "quantized_model = quantizer.quantize_model(calib_dataset=normalized_valid_dataset, weight_bit=8, activation_bit=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0236c8a",
   "metadata": {},
   "source": [
    "**Evaluate quantized model**\n",
    "\n",
    "In order to evaluate the quantized model, it needs to be re-compiled with the desired loss and evaluation metrics, such as accuracy. Since we are using 8-bit quantization we do not lose much performance, if at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26efd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05fb1fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 16s 177ms/step - loss: 11.6042 - accuracy: 0.0345\n",
      "Model evaluation accuracy (validation dataset): 3.448\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation accuracy (validation dataset): {quantized_model.evaluate(valid_dataset)[1]*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "719fd2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 177ms/step - loss: 1.7928 - accuracy: 0.5566\n",
      "Model evaluation accuracy (validation dataset): 55.655\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation accuracy (validation dataset): {quantized_model.evaluate(normalized_valid_dataset)[1]*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce297e",
   "metadata": {},
   "source": [
    "**Quantize Aware Training (QAT)**\n",
    "\n",
    "In order to improve the accuracy of the quantized model, we need to apply fine-tuning with quantize-aware training (QAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37a8a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAI INFO] Quantizing without specific `target`.\n",
      "[VAI INFO] Start CrossLayerEqualization...\n",
      "10/10 [==============================] - 10s 1s/step\n",
      "[VAI INFO] CrossLayerEqualization Done.\n",
      "[VAI INFO] Start Generation of Quantize-aware Training Model.\n",
      "[VAI INFO] Generation of Quantize-aware Training Model Done.\n"
     ]
    }
   ],
   "source": [
    "qat_model = quantizer.get_qat_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57629d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=TrainingConfig.LEARNING_RATE),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31ee5568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " quant_input_2 (VitisQuantize)  (None, 224, 224, 3)  4           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " quant_Conv1 (QuantizeWrapper)  (None, 112, 112, 16  455         ['quant_input_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " quant_Conv1_relu (QuantizeWrap  (None, 112, 112, 16  4          ['quant_Conv1[0][0]']            \n",
      " per)                           )                                                                 \n",
      "                                                                                                  \n",
      " quant_expanded_conv_depthwise   (None, 112, 112, 16  167        ['quant_Conv1_relu[0][0]']       \n",
      " (QuantizeWrapper)              )                                                                 \n",
      "                                                                                                  \n",
      " quant_expanded_conv_depthwise_  (None, 112, 112, 16  4          ['quant_expanded_conv_depthwise[0\n",
      " relu (QuantizeWrapper)         )                                ][0]']                           \n",
      "                                                                                                  \n",
      " quant_expanded_conv_project (Q  (None, 112, 112, 8)  146        ['quant_expanded_conv_depthwise_r\n",
      " uantizeWrapper)                                                 elu[0][0]']                      \n",
      "                                                                                                  \n",
      " quant_block_1_expand (Quantize  (None, 112, 112, 48  439        ['quant_expanded_conv_project[0][\n",
      " Wrapper)                       )                                0]']                             \n",
      "                                                                                                  \n",
      " quant_block_1_expand_relu (Qua  (None, 112, 112, 48  4          ['quant_block_1_expand[0][0]']   \n",
      " ntizeWrapper)                  )                                                                 \n",
      "                                                                                                  \n",
      " quant_block_1_pad (QuantizeWra  (None, 113, 113, 48  1          ['quant_block_1_expand_relu[0][0]\n",
      " pper)                          )                                ']                               \n",
      "                                                                                                  \n",
      " quant_block_1_depthwise (Quant  (None, 56, 56, 48)  487         ['quant_block_1_pad[0][0]']      \n",
      " izeWrapper)                                                                                      \n",
      "                                                                                                  \n",
      " quant_block_1_depthwise_relu (  (None, 56, 56, 48)  4           ['quant_block_1_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_1_project (Quantiz  (None, 56, 56, 16)  794         ['quant_block_1_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_2_expand (Quantize  (None, 56, 56, 96)  1639        ['quant_block_1_project[0][0]']  \n",
      " Wrapper)                                                                                         \n",
      "                                                                                                  \n",
      " quant_block_2_expand_relu (Qua  (None, 56, 56, 96)  4           ['quant_block_2_expand[0][0]']   \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_2_depthwise (Quant  (None, 56, 56, 96)  967         ['quant_block_2_expand_relu[0][0]\n",
      " izeWrapper)                                                     ']                               \n",
      "                                                                                                  \n",
      " quant_block_2_depthwise_relu (  (None, 56, 56, 96)  4           ['quant_block_2_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_2_project (Quantiz  (None, 56, 56, 16)  1562        ['quant_block_2_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_2_add (QuantizeWra  (None, 56, 56, 16)  4           ['quant_block_1_project[0][0]',  \n",
      " pper)                                                            'quant_block_2_project[0][0]']  \n",
      "                                                                                                  \n",
      " quant_block_3_expand (Quantize  (None, 56, 56, 96)  1639        ['quant_block_2_add[0][0]']      \n",
      " Wrapper)                                                                                         \n",
      "                                                                                                  \n",
      " quant_block_3_expand_relu (Qua  (None, 56, 56, 96)  4           ['quant_block_3_expand[0][0]']   \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_3_pad (QuantizeWra  (None, 57, 57, 96)  1           ['quant_block_3_expand_relu[0][0]\n",
      " pper)                                                           ']                               \n",
      "                                                                                                  \n",
      " quant_block_3_depthwise (Quant  (None, 28, 28, 96)  967         ['quant_block_3_pad[0][0]']      \n",
      " izeWrapper)                                                                                      \n",
      "                                                                                                  \n",
      " quant_block_3_depthwise_relu (  (None, 28, 28, 96)  4           ['quant_block_3_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_3_project (Quantiz  (None, 28, 28, 16)  1562        ['quant_block_3_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_4_expand (Quantize  (None, 28, 28, 96)  1639        ['quant_block_3_project[0][0]']  \n",
      " Wrapper)                                                                                         \n",
      "                                                                                                  \n",
      " quant_block_4_expand_relu (Qua  (None, 28, 28, 96)  4           ['quant_block_4_expand[0][0]']   \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " quant_block_4_depthwise (Quant  (None, 28, 28, 96)  967         ['quant_block_4_expand_relu[0][0]\n",
      " izeWrapper)                                                     ']                               \n",
      "                                                                                                  \n",
      " quant_block_4_depthwise_relu (  (None, 28, 28, 96)  4           ['quant_block_4_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_4_project (Quantiz  (None, 28, 28, 16)  1562        ['quant_block_4_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_4_add (QuantizeWra  (None, 28, 28, 16)  4           ['quant_block_3_project[0][0]',  \n",
      " pper)                                                            'quant_block_4_project[0][0]']  \n",
      "                                                                                                  \n",
      " quant_block_5_expand (Quantize  (None, 28, 28, 96)  1639        ['quant_block_4_add[0][0]']      \n",
      " Wrapper)                                                                                         \n",
      "                                                                                                  \n",
      " quant_block_5_expand_relu (Qua  (None, 28, 28, 96)  4           ['quant_block_5_expand[0][0]']   \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_5_depthwise (Quant  (None, 28, 28, 96)  967         ['quant_block_5_expand_relu[0][0]\n",
      " izeWrapper)                                                     ']                               \n",
      "                                                                                                  \n",
      " quant_block_5_depthwise_relu (  (None, 28, 28, 96)  4           ['quant_block_5_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_5_project (Quantiz  (None, 28, 28, 16)  1562        ['quant_block_5_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_5_add (QuantizeWra  (None, 28, 28, 16)  4           ['quant_block_4_add[0][0]',      \n",
      " pper)                                                            'quant_block_5_project[0][0]']  \n",
      "                                                                                                  \n",
      " quant_block_6_expand (Quantize  (None, 28, 28, 96)  1639        ['quant_block_5_add[0][0]']      \n",
      " Wrapper)                                                                                         \n",
      "                                                                                                  \n",
      " quant_block_6_expand_relu (Qua  (None, 28, 28, 96)  4           ['quant_block_6_expand[0][0]']   \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_6_pad (QuantizeWra  (None, 29, 29, 96)  1           ['quant_block_6_expand_relu[0][0]\n",
      " pper)                                                           ']                               \n",
      "                                                                                                  \n",
      " quant_block_6_depthwise (Quant  (None, 14, 14, 96)  967         ['quant_block_6_pad[0][0]']      \n",
      " izeWrapper)                                                                                      \n",
      "                                                                                                  \n",
      " quant_block_6_depthwise_relu (  (None, 14, 14, 96)  4           ['quant_block_6_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_6_project (Quantiz  (None, 14, 14, 32)  3114        ['quant_block_6_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_7_expand (Quantize  (None, 14, 14, 192)  6343       ['quant_block_6_project[0][0]']  \n",
      " Wrapper)                                                                                         \n",
      "                                                                                                  \n",
      " quant_block_7_expand_relu (Qua  (None, 14, 14, 192)  4          ['quant_block_7_expand[0][0]']   \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_7_depthwise (Quant  (None, 14, 14, 192)  1927       ['quant_block_7_expand_relu[0][0]\n",
      " izeWrapper)                                                     ']                               \n",
      "                                                                                                  \n",
      " quant_block_7_depthwise_relu (  (None, 14, 14, 192)  4          ['quant_block_7_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_7_project (Quantiz  (None, 14, 14, 32)  6186        ['quant_block_7_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_7_add (QuantizeWra  (None, 14, 14, 32)  4           ['quant_block_6_project[0][0]',  \n",
      " pper)                                                            'quant_block_7_project[0][0]']  \n",
      "                                                                                                  \n",
      " quant_block_8_expand (Quantize  (None, 14, 14, 192)  6343       ['quant_block_7_add[0][0]']      \n",
      " Wrapper)                                                                                         \n",
      "                                                                                                  \n",
      " quant_block_8_expand_relu (Qua  (None, 14, 14, 192)  4          ['quant_block_8_expand[0][0]']   \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_8_depthwise (Quant  (None, 14, 14, 192)  1927       ['quant_block_8_expand_relu[0][0]\n",
      " izeWrapper)                                                     ']                               \n",
      "                                                                                                  \n",
      " quant_block_8_depthwise_relu (  (None, 14, 14, 192)  4          ['quant_block_8_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_8_project (Quantiz  (None, 14, 14, 32)  6186        ['quant_block_8_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_8_add (QuantizeWra  (None, 14, 14, 32)  4           ['quant_block_7_add[0][0]',      \n",
      " pper)                                                            'quant_block_8_project[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " quant_block_9_expand (Quantize  (None, 14, 14, 192)  6343       ['quant_block_8_add[0][0]']      \n",
      " Wrapper)                                                                                         \n",
      "                                                                                                  \n",
      " quant_block_9_expand_relu (Qua  (None, 14, 14, 192)  4          ['quant_block_9_expand[0][0]']   \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_9_depthwise (Quant  (None, 14, 14, 192)  1927       ['quant_block_9_expand_relu[0][0]\n",
      " izeWrapper)                                                     ']                               \n",
      "                                                                                                  \n",
      " quant_block_9_depthwise_relu (  (None, 14, 14, 192)  4          ['quant_block_9_depthwise[0][0]']\n",
      " QuantizeWrapper)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_9_project (Quantiz  (None, 14, 14, 32)  6186        ['quant_block_9_depthwise_relu[0]\n",
      " eWrapper)                                                       [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_9_add (QuantizeWra  (None, 14, 14, 32)  4           ['quant_block_8_add[0][0]',      \n",
      " pper)                                                            'quant_block_9_project[0][0]']  \n",
      "                                                                                                  \n",
      " quant_block_10_expand (Quantiz  (None, 14, 14, 192)  6343       ['quant_block_9_add[0][0]']      \n",
      " eWrapper)                                                                                        \n",
      "                                                                                                  \n",
      " quant_block_10_expand_relu (Qu  (None, 14, 14, 192)  4          ['quant_block_10_expand[0][0]']  \n",
      " antizeWrapper)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_10_depthwise (Quan  (None, 14, 14, 192)  1927       ['quant_block_10_expand_relu[0][0\n",
      " tizeWrapper)                                                    ]']                              \n",
      "                                                                                                  \n",
      " quant_block_10_depthwise_relu   (None, 14, 14, 192)  4          ['quant_block_10_depthwise[0][0]'\n",
      " (QuantizeWrapper)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_10_project (Quanti  (None, 14, 14, 48)  9274        ['quant_block_10_depthwise_relu[0\n",
      " zeWrapper)                                                      ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_11_expand (Quantiz  (None, 14, 14, 288)  14119      ['quant_block_10_project[0][0]'] \n",
      " eWrapper)                                                                                        \n",
      "                                                                                                  \n",
      " quant_block_11_expand_relu (Qu  (None, 14, 14, 288)  4          ['quant_block_11_expand[0][0]']  \n",
      " antizeWrapper)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_11_depthwise (Quan  (None, 14, 14, 288)  2887       ['quant_block_11_expand_relu[0][0\n",
      " tizeWrapper)                                                    ]']                              \n",
      "                                                                                                  \n",
      " quant_block_11_depthwise_relu   (None, 14, 14, 288)  4          ['quant_block_11_depthwise[0][0]'\n",
      " (QuantizeWrapper)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_11_project (Quanti  (None, 14, 14, 48)  13882       ['quant_block_11_depthwise_relu[0\n",
      " zeWrapper)                                                      ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_11_add (QuantizeWr  (None, 14, 14, 48)  4           ['quant_block_10_project[0][0]', \n",
      " apper)                                                           'quant_block_11_project[0][0]'] \n",
      "                                                                                                  \n",
      " quant_block_12_expand (Quantiz  (None, 14, 14, 288)  14119      ['quant_block_11_add[0][0]']     \n",
      " eWrapper)                                                                                        \n",
      "                                                                                                  \n",
      " quant_block_12_expand_relu (Qu  (None, 14, 14, 288)  4          ['quant_block_12_expand[0][0]']  \n",
      " antizeWrapper)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_12_depthwise (Quan  (None, 14, 14, 288)  2887       ['quant_block_12_expand_relu[0][0\n",
      " tizeWrapper)                                                    ]']                              \n",
      "                                                                                                  \n",
      " quant_block_12_depthwise_relu   (None, 14, 14, 288)  4          ['quant_block_12_depthwise[0][0]'\n",
      " (QuantizeWrapper)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_12_project (Quanti  (None, 14, 14, 48)  13882       ['quant_block_12_depthwise_relu[0\n",
      " zeWrapper)                                                      ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_12_add (QuantizeWr  (None, 14, 14, 48)  4           ['quant_block_11_add[0][0]',     \n",
      " apper)                                                           'quant_block_12_project[0][0]'] \n",
      "                                                                                                  \n",
      " quant_block_13_expand (Quantiz  (None, 14, 14, 288)  14119      ['quant_block_12_add[0][0]']     \n",
      " eWrapper)                                                                                        \n",
      "                                                                                                  \n",
      " quant_block_13_expand_relu (Qu  (None, 14, 14, 288)  4          ['quant_block_13_expand[0][0]']  \n",
      " antizeWrapper)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_13_pad (QuantizeWr  (None, 15, 15, 288)  1          ['quant_block_13_expand_relu[0][0\n",
      " apper)                                                          ]']                              \n",
      "                                                                                                  \n",
      " quant_block_13_depthwise (Quan  (None, 7, 7, 288)   2887        ['quant_block_13_pad[0][0]']     \n",
      " tizeWrapper)                                                                                     \n",
      "                                                                                                  \n",
      " quant_block_13_depthwise_relu   (None, 7, 7, 288)   4           ['quant_block_13_depthwise[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (QuantizeWrapper)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_13_project (Quanti  (None, 7, 7, 80)    23130       ['quant_block_13_depthwise_relu[0\n",
      " zeWrapper)                                                      ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_14_expand (Quantiz  (None, 7, 7, 480)   38887       ['quant_block_13_project[0][0]'] \n",
      " eWrapper)                                                                                        \n",
      "                                                                                                  \n",
      " quant_block_14_expand_relu (Qu  (None, 7, 7, 480)   4           ['quant_block_14_expand[0][0]']  \n",
      " antizeWrapper)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_14_depthwise (Quan  (None, 7, 7, 480)   4807        ['quant_block_14_expand_relu[0][0\n",
      " tizeWrapper)                                                    ]']                              \n",
      "                                                                                                  \n",
      " quant_block_14_depthwise_relu   (None, 7, 7, 480)   4           ['quant_block_14_depthwise[0][0]'\n",
      " (QuantizeWrapper)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_14_project (Quanti  (None, 7, 7, 80)    38490       ['quant_block_14_depthwise_relu[0\n",
      " zeWrapper)                                                      ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_14_add (QuantizeWr  (None, 7, 7, 80)    4           ['quant_block_13_project[0][0]', \n",
      " apper)                                                           'quant_block_14_project[0][0]'] \n",
      "                                                                                                  \n",
      " quant_block_15_expand (Quantiz  (None, 7, 7, 480)   38887       ['quant_block_14_add[0][0]']     \n",
      " eWrapper)                                                                                        \n",
      "                                                                                                  \n",
      " quant_block_15_expand_relu (Qu  (None, 7, 7, 480)   4           ['quant_block_15_expand[0][0]']  \n",
      " antizeWrapper)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_15_depthwise (Quan  (None, 7, 7, 480)   4807        ['quant_block_15_expand_relu[0][0\n",
      " tizeWrapper)                                                    ]']                              \n",
      "                                                                                                  \n",
      " quant_block_15_depthwise_relu   (None, 7, 7, 480)   4           ['quant_block_15_depthwise[0][0]'\n",
      " (QuantizeWrapper)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_15_project (Quanti  (None, 7, 7, 80)    38490       ['quant_block_15_depthwise_relu[0\n",
      " zeWrapper)                                                      ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_15_add (QuantizeWr  (None, 7, 7, 80)    4           ['quant_block_14_add[0][0]',     \n",
      " apper)                                                           'quant_block_15_project[0][0]'] \n",
      "                                                                                                  \n",
      " quant_block_16_expand (Quantiz  (None, 7, 7, 480)   38887       ['quant_block_15_add[0][0]']     \n",
      " eWrapper)                                                                                        \n",
      "                                                                                                  \n",
      " quant_block_16_expand_relu (Qu  (None, 7, 7, 480)   4           ['quant_block_16_expand[0][0]']  \n",
      " antizeWrapper)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_16_depthwise (Quan  (None, 7, 7, 480)   4807        ['quant_block_16_expand_relu[0][0\n",
      " tizeWrapper)                                                    ]']                              \n",
      "                                                                                                  \n",
      " quant_block_16_depthwise_relu   (None, 7, 7, 480)   4           ['quant_block_16_depthwise[0][0]'\n",
      " (QuantizeWrapper)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_16_project (Quanti  (None, 7, 7, 160)   76970       ['quant_block_16_depthwise_relu[0\n",
      " zeWrapper)                                                      ][0]']                           \n",
      "                                                                                                  \n",
      " quant_last_conv (QuantizeWrapp  (None, 7, 7, 1000)  161007      ['quant_block_16_project[0][0]'] \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " quant_last_relu (QuantizeWrapp  (None, 7, 7, 1000)  4           ['quant_last_conv[0][0]']        \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " quant_global_average_pool (Qua  (None, 1000)        4           ['quant_last_relu[0][0]']        \n",
      " ntizeWrapper)                                                                                    \n",
      "                                                                                                  \n",
      " quant_dense (QuantizeWrapper)  (None, 29)           29036       ['quant_global_average_pool[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " quant_dense_softmax (QuantizeW  (None, 29)          4           ['quant_dense[0][0]']            \n",
      " rapper)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 662,975\n",
      "Trainable params: 662,357\n",
      "Non-trainable params: 618\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(qat_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e97f1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model based on highest validation_accuracy.\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=TrainingConfig.CHECKPOINT_DIR,\n",
    "                                                               save_weights_only=False,\n",
    "                                                               monitor='val_accuracy',\n",
    "                                                               mode='max',\n",
    "                                                               save_best_only=True,\n",
    "                                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80569f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 08:25:39.244137\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "timestamp1 = datetime.now()\n",
    "print(timestamp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db8d0c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "182/182 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses while saving (showing 5 of 252). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models_asl_classifier25/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models_asl_classifier25/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 458s 2s/step - loss: 0.1131 - accuracy: 0.9710 - val_loss: 0.0468 - val_accuracy: 0.9848\n",
      "Epoch 2/16\n",
      "182/182 [==============================] - 216s 1s/step - loss: 0.0559 - accuracy: 0.9833 - val_loss: 0.3381 - val_accuracy: 0.8993\n",
      "Epoch 3/16\n",
      "182/182 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses while saving (showing 5 of 252). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models_asl_classifier25/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models_asl_classifier25/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 410s 2s/step - loss: 0.0422 - accuracy: 0.9876 - val_loss: 0.0232 - val_accuracy: 0.9924\n",
      "Epoch 4/16\n",
      "182/182 [==============================] - 217s 1s/step - loss: 0.0797 - accuracy: 0.9798 - val_loss: 0.2162 - val_accuracy: 0.9407\n",
      "Epoch 5/16\n",
      "182/182 [==============================] - 217s 1s/step - loss: 0.1105 - accuracy: 0.9655 - val_loss: 0.0595 - val_accuracy: 0.9848\n",
      "Epoch 6/16\n",
      "182/182 [==============================] - 217s 1s/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0600 - val_accuracy: 0.9834\n",
      "Epoch 7/16\n",
      "182/182 [==============================] - 216s 1s/step - loss: 0.0495 - accuracy: 0.9841 - val_loss: 0.0700 - val_accuracy: 0.9807\n",
      "Epoch 8/16\n",
      "182/182 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses while saving (showing 5 of 252). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 398s 2s/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.0229 - val_accuracy: 0.9931\n",
      "Epoch 9/16\n",
      "182/182 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses while saving (showing 5 of 252). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models_asl_classifier25/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models_asl_classifier25/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 399s 2s/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0254 - val_accuracy: 0.9938\n",
      "Epoch 10/16\n",
      "182/182 [==============================] - ETA: 0s - loss: 1.4438e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as Conv1_layer_call_fn, Conv1_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, Conv1_relu_layer_call_fn, Conv1_relu_layer_call_and_return_conditional_losses while saving (showing 5 of 252). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models_asl_classifier25/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models_asl_classifier25/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 399s 2s/step - loss: 1.4438e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9952\n",
      "Epoch 11/16\n",
      "182/182 [==============================] - 216s 1s/step - loss: 7.5498e-05 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9945\n",
      "Epoch 12/16\n",
      "182/182 [==============================] - 216s 1s/step - loss: 4.6995e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9952\n",
      "Epoch 13/16\n",
      "182/182 [==============================] - 216s 1s/step - loss: 3.5818e-05 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9952\n",
      "Epoch 14/16\n",
      "182/182 [==============================] - 216s 1s/step - loss: 2.8991e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9952\n",
      "Epoch 15/16\n",
      "182/182 [==============================] - 217s 1s/step - loss: 2.4469e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9952\n",
      "Epoch 16/16\n",
      "182/182 [==============================] - 216s 1s/step - loss: 2.0376e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# Then run the training process with this qat_model to get the quantize finetuned model.\n",
    "qat_results = qat_model.fit(normalized_train_dataset,#train_dataset,\n",
    "              validation_data=normalized_valid_dataset,#valid_dataset,\n",
    "              epochs=16,#TrainingConfig.EPOCHS,\n",
    "              workers=4,\n",
    "              use_multiprocessing=True, \n",
    "              callbacks=model_checkpoint_callback,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4fe1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 09:39:45.085975\n",
      "1:14:05.841838\n"
     ]
    }
   ],
   "source": [
    "timestamp2 = datetime.now()\n",
    "print(timestamp2)\n",
    "\n",
    "print(timestamp2-timestamp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfeada33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(metrics, ylabel=None, ylim=None, metric_name=None, color=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 4))\n",
    "\n",
    "    if not (isinstance(metric_name, list) or isinstance(metric_name, tuple)):\n",
    "        metrics = [metrics,]\n",
    "        metric_name = [metric_name,]\n",
    "        \n",
    "    for idx, metric in enumerate(metrics):    \n",
    "        ax.plot(metric, color=color[idx])\n",
    "    \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(ylabel)\n",
    "    plt.xlim([0, TrainingConfig.EPOCHS-1])\n",
    "    plt.ylim(ylim)\n",
    "    # Tailor x-axis tick marks\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    plt.grid(True)\n",
    "    plt.legend(metric_name)   \n",
    "    plt.show(block=block_plot)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9297f154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNoAAAGHCAYAAABmoz/EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAA9hAAAPYQGoP6dpAABg8klEQVR4nO3de3zO9f/H8ee188Ymhm2YOZ9P2SRyTA5ziBBScgxfh0h9HZKir+JXkSTKtw05RE5FCXMWyiFDSHIaNhZiGNts1++P67ur1g42Ptvlujzut9t187k+1+fz/ryu6+VT357fz+fzNpnNZrMAAAAAAAAA3BcnWxcAAAAAAAAAOAKCNgAAAAAAAMAABG0AAAAAAACAAQjaAAAAAAAAAAMQtAEAAAAAAAAGIGgDAAAAAAAADEDQBgAAAAAAABiAoA0AAAAAAAAwAEEbAAAAAAAAYACCNgAAABuYPn26TCaTqlWrZutSAAAAYBCCNgAAABsIDw+XJB0+fFg//fSTjasBAACAEQjaAAAA8tjevXt14MABtWnTRpIUFhZm44oyFh8fb+sSAAAA7ApBGwAAQB5LDdYmT56s+vXra/HixelCrfPnz6t///4KDAyUm5ubihUrps6dO+vixYvWba5evapXX31VZcqUkbu7u4oWLarWrVvr119/lSRt2bJFJpNJW7ZsSTP26dOnZTKZNHfuXOu6Xr16KX/+/Dp06JBatGghb29vNWvWTJIUERGh9u3bq0SJEvLw8FC5cuU0YMAAXbp0Kd13+/XXX/Xcc8/Jz89P7u7uKlmypF588UUlJCTo9OnTcnFx0aRJk9Ltt23bNplMJi1duvSeflMAAIAHgYutCwAAAHiY3Lp1S19++aXq1KmjatWqqU+fPurXr5+WLl2qnj17SrKEbHXq1FFSUpJef/111ahRQ5cvX9a6dev0559/ys/PT9evX1eDBg10+vRpjRo1SnXr1tWNGze0bds2xcTEqFKlSjmuLTExUU8//bQGDBig0aNH686dO5KkEydOqF69eurXr58KFCig06dPa+rUqWrQoIEOHTokV1dXSdKBAwfUoEEDFS5cWG+//bbKly+vmJgYrVq1SomJiSpVqpSefvppffrppxo5cqScnZ2tx54xY4aKFSumZ555xoBfGQAAwDYI2gAAAPLQsmXLdO3aNfXt21eS1LVrVw0fPlxhYWHWoO3NN9/UpUuXdODAAVWuXNm6b5cuXazL06ZN0+HDhxUREaGnnnrKur5jx473XFtSUpLefPNN9e7dO836gQMHWpfNZrPq16+vJk2aKCgoSN9//72efvppSdKIESPk4uKi3bt3q0iRItZ9nn/+eevyyy+/rKZNm2r16tXq0KGDJCk6OlorV67UuHHj5OLC/zwFAAD2i1tHAQAA8lBYWJg8PT3VrVs3SVL+/Pn17LPPavv27Tp+/Lgk6fvvv1fTpk3ThGz/9P3336tChQppQjYjdOrUKd262NhYDRw4UIGBgXJxcZGrq6uCgoIkSUePHpVkeZ7b1q1b1aVLlzQh2z81adJENWvW1CeffGJd9+mnn8pkMql///6GfhcAAIC8RtAGAACQR37//Xdt27ZNbdq0kdls1tWrV3X16lV17txZ0l8zkf7xxx8qUaJElmNlZ5uc8vLyko+PT5p1KSkpatGihVasWKGRI0dq48aN2r17t3788UdJllthJenPP/9UcnJytmp6+eWXtXHjRh07dkxJSUn673//q86dO8vf39/Q7wMAAJDXCNoAAADySHh4uMxms5YtW6aCBQtaX6mzj86bN0/JyckqUqSIzp07l+VY2dnGw8NDkpSQkJBmfUaTGEiSyWRKt+6XX37RgQMH9P7772vo0KFq0qSJ6tSpI19f3zTbFSpUSM7OznetSZK6d+8uX19fffLJJ1q6dKkuXLigwYMH33U/AACABx1BGwAAQB5ITk7WvHnzVLZsWW3evDnd69VXX1VMTIy+//57hYaGavPmzTp27Fim44WGhuq3337Tpk2bMt2mVKlSkqSDBw+mWb9q1aps150avrm7u6dZ/9lnn6V57+npqcaNG2vp0qWZBnmpPDw81L9/f82bN09Tp05VrVq19MQTT2S7JgAAgAcVT5sFAADIA99//72io6P1f//3f2rSpEm6z6tVq6YZM2YoLCxMM2bM0Pfff69GjRrp9ddfV/Xq1XX16lWtXbtWI0aMUKVKlTR8+HAtWbJE7du31+jRo/XYY4/p1q1b2rp1q9q2baumTZvK399fTz31lCZNmqSCBQsqKChIGzdu1IoVK7Jdd6VKlVS2bFmNHj1aZrNZhQoV0urVqxUREZFu29SZSOvWravRo0erXLlyunjxolatWqXPPvtM3t7e1m0HDRqk9957T/v27dPnn39+T78pAADAg4Yr2gAAAPJAWFiY3Nzc0s3omapw4cJ65pln9O2331pn7mzbtq0mT56sVq1aaejQobp27ZoKFSokSfL29tYPP/ygvn37avbs2WrTpo1eeuklHTt2TMWKFbOOO3/+fDVr1kyjRo3Ss88+q/Pnz+vLL7/Mdt2urq5avXq1KlSooAEDBui5555TbGysNmzYkG7bmjVravfu3QoODtaYMWPUqlUrjRo1Su7u7nJzc0uzbfHixdWgQQMVKlRI3bt3z3Y9AAAADzKT2Ww227oIAAAAPFxiY2MVFBSkoUOH6r333rN1OQAAAIbg1lEAAADkmXPnzunkyZN6//335eTkpGHDhtm6JAAAAMNw6ygAAADyzOeff64mTZro8OHDWrhwoYoXL27rkgAAAAzDraMAAAAAAACAAWx6Rdu2bdvUrl07FStWTCaTSV9//fVd99m6dauCg4Pl4eGhMmXK6NNPP839QgEAAAAAAIC7sGnQdvPmTdWsWVMzZszI1vanTp1S69at1bBhQ+3fv1+vv/66Xn75ZS1fvjyXKwUAAAAAAACy9sDcOmoymbRy5Up16NAh021GjRqlVatW6ejRo9Z1AwcO1IEDB7Rr1648qBIAAAAAAADImF3NOrpr1y61aNEizbqWLVsqLCxMSUlJcnV1TbdPQkKCEhISrO9TUlJ05coV+fr6ymQy5XrNAAAAAAAAeHCZzWZdv35dxYoVk5PT/d38aVdB24ULF+Tn55dmnZ+fn+7cuaNLly4pICAg3T6TJk3ShAkT8qpEAAAAAAAA2KGzZ8+qRIkS9zWGXQVtktJdhZZ652tmV6eNGTNGI0aMsL6/du2aSpYsqd9++02FChXKvUKRJ24l3dLSI0t1+cRlDWg9QF4eXrYuKdvMZrMux1/WuevndObaGZ27fk5nr521LMed09m4s7qReOOu4xT0LKhAn0DLq0CgSvqUVAmfEiqev7jcXNzk6uQqFycXuTi7yNVkWXZ1cpWLs4tlvZOLnEx/JfZ37ki3bllet29L8fFSQoJ065YpzXqTSXJ1tbxcXCyv1GVXV8nZ2WxdtrzPeHtXV8tYqZKSkrR582Y1bdrUepVqSoqUlGSp7c6dv5b/uS4pSUpJMVmXM9r+wbhZ/uGRnJysw4cPa9CgSipaNP1Vx7AvGZ2fsG/01LHQT8dCPx0L/XQ89NSxXLlyRRUqVJC3t/d9j2VXQZu/v78uXLiQZl1sbKxcXFzk6+ub4T7u7u5yd3dPt75QoUKZ7gP7cObqGXVa3kn7YvZJkj5Z8IlalWultuXbqlW5VvL1evD6++etP7Xh5AatO7FOa4+v1/mL8VKKq5TsavkzxeV/y+5SSiUp2VWPuBWVn1dxFfUopsLuxeTr7i9fdz894lZEj7gWlovJ0xIs3ZDuXLWESWeSpN+TLKFYfPxfwVnqckbrUpfv3Mn738XJ6e8hnFmJiZ1lMrkoKclEOOYQmqhHjyRVrsz/ALF3SUlJ8vLykq+vL/+D0kHQU8dCPx0L/XQs9NPx0FPHZMQjxuwqaKtXr55Wr16dZt369esVEhLi8H+xzWbpgw+kgADphRdsXY3tbTi5Qd2WddPlW5dV0KOgkpOSdfX2VS3+ZbEW/7JYTiYn1Q+sr7bl26pthbaqUqSKTZ7Jl5ySrL3Re7X297Vad2KdfozaK/PpBtKRztLRidJN/7uOcfV/r2O5XGtGPD3/enl5/bXs4WH5O/n3K8n+ftVYVssZhWYpKZar5iyPUzRJuvv5nDacy/6ys7PRvxKyYjan6NKly8qf/xFblwIAAAAAuc6mQduNGzf0+++/W9+fOnVKkZGRKlSokEqWLKkxY8bo/Pnz+uKLLyRZZhidMWOGRowYoZdeekm7du1SWFiYvvzyS1t9hTyzcaM0cqRluUgRqWVL29ZjK2azWe/vfF9jNo5RijlFwQHBWtxxsQ7+cFBFahbR2pNr9e3xb3Xw4kH9EPWDfoj6QaM3jlapR0pZQ7fGpRrLw8Uj12qMvh6tdb+v09oTa7Xh5AZduREnnW4iHekpHf1aii+aZntn55wFRdlddnVNH5DlZNnDI+0tnUZJvQ00s0AuPj5J27dvU7NmjeTp6Zrp97zP51MijyQlJWvNmp0qX761rUsBAAAAgFxn06Bt7969atq0qfV96rPUevbsqblz5yomJkZRUVHWz0uXLq01a9bolVde0SeffKJixYpp+vTp6tSpU57Xntc+/fSv5RdflA4ckPzvfjGUQ7mecF19VvXRsiPLJEm9a/XWzDYz5Wx21mHTYT1e4nE1LN1Q7zR7R1HXovTdb9/p2+PfauPJjTp99bRm7JmhGXtmKJ9rPjUv21xty7dV6/KtFeCdfhKNnLh957Z+iPrBGq79EvuLdMdVOtVMOvKeTL8+I/Otv54H6OsrPfOM1Lmz1LSp5OZ2X4e3O05Okru75ZWRpCTp5MkbKlPGEqoBAAAAAGAvbBq0NWnSxDqZQUbmzp2bbl3jxo31888/52JVtmc2m3X19lWdjTurs9fO6peTl7Vi5fOSnOVd9LJiY33VqdsNbdngKVeXh+M+uN8u/6ZnljyjI38ckauTq6aHTteA4AEymUxKSkpKt33JAiX1rzr/0r/q/Es3E29q06lN+va3b/Xt8W8VfT1aX//6tb7+9WtJUkixEOvVbo8GPJpmYoCMmM1m/Xb5N607sU7rTqzT5lObdevOLemOm3SiuXTkVTkf76jkeB/L9rJchdixoyVca9LEckUWAAAAADwozGaz7ty5o+TkZFuXYheSkpLk4uKi27dv85vZAWdnZ7m4uOTJI6Ue2v/cT0mx3bHjk+J19tpZa5AWdS3Ksvy/9+lmm9z2upTiLAX+oOvt+kuz92rn1vzK326cHu+6TXWK1VGdYnUUUixEZQqWscmzyHLTqmOr1GNlD8UlxKmYdzEte3aZ6gXWy/b++dzyqV3FdmpXsZ3MZrMiL0RaQ7fd53drb/Re7Y3eq/Fbxysgf4DalG+jthXa6qkyTymfWz5JUlxCnDae3GgN105fPW0ZPMlDOtFCHr+9qORfQ5UUb5n1NFmWKw47dbKEaw0b8mwwAAAAAA+mxMRExcTEKD4+3tal2A2z2Sx/f3+dPXvW4f4b3FF5eXkpICBAbrl8W9lDG7Rt3GhSt27Gj5uUnKTz18+nDdBSQ7U4y7ort65ka6zCXoVVIn+Qjh0cpluSuvT8U8UbtNLqGzP0+xcjlbj+TW0r8YS2lZhi3aeQZyGFFAtRSECI6hS3hG/FvYvb9MT/6CPp7bel5OS0zwC76zPCPFO0I2aDNp6NkFw7q6J/kEY2Hqq4IwW17dRf27q6SjduuGYrPDWZTHo04FE9GvCoxjUepws3LmjN8TX69rdvtf7EesXciNHn+z/X5/s/l7uzu5qUaqL4pHjtOrdLd1L+Nx1noqdcTnaR76kB+vNgAyXectPt/41fvPhf4Vr9+oRrAAAAAB5sKSkpOnXqlJydnVWsWDG5ubkRHGVDSkqKbty4ofz588uJB0g/0MxmsxITE/XHH3/o1KlTKl++fK727KEN2j791MmwoO3KrStadWyVlh9drogTEUpITrjrPvnd8qtkgZIK9AlUoE+gZbmAZTmwQKBK+JSQl6uXvvtOantJKlRImje2nTw82mlKC6lLfIqWLXNVkbUb1H7qBB24ul0HLh7QlVtXtP7Eeq0/sd56LP/8/tYr3lL/LJKviDFf/i6+/FIaPvyv99eu5WRvJ0kt/veyzLrZd3ZG27lKaq0XXzSrYEHLM9B8fS2/WUbLad/7q3etPurzaB8l3EnQ1jNbLVe7/fatTl09pXUn1lkOkZBPARcGK9/xnjq7r7oSbrno4v+OHhhoCdY6d5Yef5yH9AMAAACwH4mJiUpJSVFgYKC8vLxsXY7dSElJUWJiojw8PAja7ICnp6dcXV115swZa99yy0MbtG3d6qRDh6Tq1e9t/4s3LurrX7/W8qPLtfn05r+udpLk5uxmDcwyC9IKuBfI1v9LkDoJQq9ellkgJctMkP/9r5P27JHOnPHRzZVT9NNCKSklUYcuHtKe6D3aG71Xe6L36HDsYV24cUGrf1ut1b+tto4bVCBIdYr/dctpcECwCngUuLcfIxM7dljqlqRhw6R//Uu6dcvyio/PfPnMpYv6KnK1rt1IknNyfoUUaagibqUy3T4+3qz4eJNSUky6fFm6fDlndbq5pYZu7ipUqIV8fVvoyUIfyex5WRfu/KroX4vr6I9Birn91z88S5WSnn3WEq7VqZM7s3MCAAAAQF4hLIKjy6u/4w9t0CZJ06ZJYWHZ3/5c3DmtOLpCy48u1/Yz22XWXxM51PCroU6VO6lj5Y6qUqTKXR+onx1RUdKaNZbl/v3TfvbII5arxRo2tPzZvLnUu7ebgosFK7hYsHW7+KR4RV6I1J7ze7Q3Zq/2nN+jY5eP6cy1Mzpz7Yx1Bs/U7/BC9RfUo2YP+ee/vylNT5yQOnSQEhOl9u2lKVOydxvlokOL9M6qfrrV5JZKPVJKK7uuVC3/Ulnuk5R0R998s1aPPdZK16+7WsO2K1dkXf7n+9TlxETLKybG8vqLSVJhSQ2sa8qW/Stcq12bcA0AAAAAAKT1UAdtCxdKkyZJRYtmvs3JP09q+ZHlWn50uX46/1Oaz+oUq6NOlTupU5VOKleonOH1ff65ZdKGJ5+UKlZM/3m9epZnn40dKw0ZYnlfqVLabbxcvVQ/sL7qB9a3rrt2+5p+jvk5zZVvp6+e1sGLBzXy4kiN2ThGoeVD1btWb7Wt0FZuzjl7UOCff0pt2kiXLknBwZbf+W4hW1JykkZGjNS0n6ZJklqWbalFnRapkGehbB3T1TVFAQFSyZLZr9Nslm7ezDqUu3LFMmbnzlKNGoRrAAAAAAAgcw9t0Fa7dop+/lmaNUt66620nx3946iWH7WEa5EXIq3rTTLpiZJPWK9cK1kgB6lODiUlWYI2SRowIPPtRo2SNm6UNm2SunWTfvzxr1tMM1PAo4Calm6qpqWbWtf9cfMPff3r15oTOUe7zu2yPqessFdhPV/9efWu1Vs1/Wvete7ERMtkAMeOSSVKSKtWSfnyZb3PxRsX1XVZV209s1WSNLbhWE1oMkHOTrk7k4DJJOXPb3kFBeXqoQAAAAAAdqBJkyaqVauWpk2blq3tT58+rbJly2r//v2qVatWrtYG+/DQBm0DB6aof39p5kxp5Eizjl07YL1y7eilo9btnE3OalKqiTpV7qQOlToowDsgT+pbvdpyK2PRopZbMDPj7CzNny/VrCkdOGAJ3j76KOfHK5KviF4KfkkvBb+kXy/9qrmRc/XFgS8UcyNGH/30kT766SPVDqit3rV6q3v17hleaWY2SwMHSps3W8Kr776TihXL+rg/nftJnb7qpPPXz8vbzVvzOszTM5WfyfkXAAAAAAA8NO72zPOePXtq7ty5OR53xYoVcnV1zfb2gYGBiomJUeHChXN8rHvVokULbdy4UTt27NDjjz+eZ8dF9jy0QVvbtikqGpCg2Bh3BfUdrT8qvmf9zNXJVc3LNlenyp30dMWnVdgr706YVKmTIPTta3lYf1aKFZPmzpXatpWmT5eeekpq1+7ej12pcCVNfmqyJj45UetPrNecyDn65tdv9HPMz/o55me9uv5Vta/YXr1r9VaLsi2sV55NnizNmWOZdXPJEsutllmZvW+2hn4/VInJiapUuJJWdl2pSoUrZb0TAAAAAOChF/O3h2wvWbJEb775po4dO2Zd5+npmWb7pKSkbAVohQpl7/FFqZydneXvf3/POM+JqKgo7dq1S0OGDFFYWJjNg7bs/q4Pk4d2WpGQOTUVW3WcJOmPjc/L3dlDz1R6RgueWaA//v2Hvuv+nfo82scmIduJE1JEhOXWxpdeyt4+bdpIw4dblnv3ls6fv/86XJxc1Lp8ay19dqliXo3R9FbT9aj/o0pMTtTSI0vVelFrlZxWUmM2jNG0sGi9/rplv+nTpdatMx834U6CXlr1kgZ8O0CJyYnqWLmjdvfbTcgGAAAAAA8As9msm4k3bfIym813L1CSv7+/9VWgQAGZTCbr+9u3b+uRRx7RV199pSZNmsjDw0MLFizQ5cuX9dxzz6lEiRLy8vJS9erV9eWXX6YZt0mTJhqe+h/XkkqVKqV3331Xffr0kbe3t0qWLKnZs2dbPz99+rRMJpMiIyMlSVu2bJHJZNLGjRsVEhIiLy8v1a9fP00IKEkTJ05U0aJF5e3trX79+mn06NHZuvV0zpw5atu2rf71r39pyZIlunnzZprPr169qv79+8vPz08eHh6qVq2avv32W+vnO3bsUOPGjeXl5aWCBQuqZcuW+vPPP63f9Z+3zNaqVUvjx4+3vjeZTPr000/Vvn175cuXTxMnTlRycrL69u2r0qVLy9PTUxUrVtRHGdxqFx4erqpVq8rd3V0BAQEaMmSIJKlPnz5q27Ztmm3v3Lkjf39/hYeH3/U3edA8tFe0RV+PVr56X+r29reVHFtDy0KuqG0rz7vvmAdSz9lWraTSpbO/3+TJ0tat0v790vPPW57dlp2ZPrPD18tXQ+sO1dC6Q3XgwgHNiZyjBQcXKPp6tCYv3izNtTzortlzv6hHv5KSfDIc5+y1s+q8tLN2n98tJ5OT3nnyHY16YtRdL/sFAAAAAOSN+KR45Z+U3ybHvjHmhvK53eVB39k0atQoTZkyRXPmzJG7u7tu376t4OBgjRo1Sj4+Pvruu+/Uo0cPlSlTRnXr1s10nClTpug///mPXn/9dS1btkz/+te/1KBBAxXL4llJY8eO1ZQpU1SkSBENHDhQffr00Y4dOyRJCxcu1DvvvKOZM2fqiSee0OLFizVlyhSVvksAYDabNWfOHH3yySeqVKmSKlSooK+++kq9e/eWJKWkpCg0NFTXr1/XggULVLZsWR05ckTO/wsGIiMj1axZM/Xp00fTp0+Xi4uLNm/erOTk5Bz9rm+99ZYmTZqkDz/8UM7OzkpJSVGJEiX01VdfqXDhwtq5c6f69++vgIAAdenSRZI0a9YsjRgxQpMnT1ZoaKiuXbtm/T369eunRo0aKSYmRgEBlsd1rVmzRjdu3LDub08e2qBtwTML1Kl2J712xUOffCJ9OsNTbVvZuiopIUFKDWyzmgQhI+7u0uLFUu3alsBt0iTpjTeMr7Gmf01NazVN7zV/T59v3KhXptZTYrKHVGGVNpZ/RgFTPNSpcif1rtVbjUs1lpPJcuHkltNb1GVpF/0R/4cKeRbSl52+VIuyLYwvEAAAAADw0Bs+fLg6duyYZt1rr71mXR46dKjWrl2rpUuXZhm0tW7dWoMGDZJkCe8+/PBDbdmyRd27d890n3feeUeNGzeWJI0ePVpt2rTR7du35eHhoY8//lh9+/a1BmRvvvmm1q9frxs3bmT5fTZs2KD4+Hi1bNlSkvTCCy8oLCzMOs6GDRu0e/duHT16VBUqVJAklSlTxrr/e++9p5CQEM2cOdO6rmrVqlkeMyPdu3dXnz590qybMGGCdbl06dLauXOnvvrqK2tQNnHiRL366qsaNmyYdbs6depIkurXr6+KFStq/vz5GjlypCTLlXvPPvus8ue3TeB7Px7aoK1V2VbycPHQsGGWCRG++84yU2bFirata8UK6dIlqXhxy+2gOVWhguX79OwpjR8vNW0qPfGE4WVKkuKvu2nG8FAlxklVaySp6wcntOi3Cvr10q+af3C+5h+cr9KPlFbPmj3l5uymcZvHKdmcrFr+tbSiywqVLpiDy/UAAAAAAHnCy9VLN8ZkHfrk5rGNEhISkuZ9cnKyJk+erCVLluj8+fNKSEhQQkKC8uXL+gq6Gn97AHnqLap//PFHtvdJvUorNjZWJUuW1LFjx6zBXarHHntMmzZtynLMsLAwde3aVS4ulijnueee07///W8dO3ZMFStWVGRkpEqUKGEN2f4pMjJSzz77bJbHyI5//q6S9Omnn+rzzz/XmTNndOvWLSUmJlpvhY2NjVV0dLSaNWuW6Zj9+vXT7NmzNXLkSMXGxuq7777Txo0b77tWW3hon9GWqnx5yyQC0r3N1mm01EkQXnpJcrnHGLRHD8uto8nJUvfu0v9utzZUUpL07LPS0aOWyRjWfueqcc1f0ZFBR7Sr7y71r91fPu4+OnX1lMZvHa/XN72uZHOyetTooR19dhCyAQAAAMADymQyKZ9bPpu8jHys0D8DtClTpujDDz/UyJEjtWnTJkVGRqply5ZKTEzMcpx/PuzfZDIpJSUl2/ukfqe/7/PP73m3Z9NduXJFX3/9tWbOnCkXFxe5uLioePHiunPnjvU5Zv+cAOKf7va5k5NTujqSkpLSbffP3/Wrr77SK6+8oj59+mj9+vWKjIxU7969rb/r3Y4rSS+++KJOnjypXbt2acGCBSpVqpQaNmx41/0eRA990CZJr7xi+XPePOnKFdvVcfSotG2b5blq/frd+zgmkzRrllS2rBQVZRkrm8+TzBazWRo8WNqwQcqXT/r2W6lEidRjm/R4icf1WbvPFPNqjBY8s0DNSjdTAfcCmt5quuZ1mGfo/0MBAAAAAEB2bN++Xe3bt9cLL7ygmjVrqkyZMjp+/Hie11GxYkXt3r07zbq9e/dmuc/ChQtVokQJHThwQJGRkdbXtGnTNG/ePN25c0c1atTQuXPn9Ntvv2U4Ro0aNbK8SqxIkSJpZnONi4vTqVOn7vp9tm/frvr162vQoEF69NFHVa5cOZ04ccL6ube3t0qVKpXlsX19fdWhQwfNmTNHc+bMsd4Oa48I2iQ1aSLVrCnFx/81EYEtfPaZ5c927Sy3jt4Pb2/L89pcXS23o6aObYQPPpD++1/JyUn68kvp0Ucz3s7L1UvP13heG17coKujr2po3aFMegAAAAAAsIly5copIiJCO3fu1NGjRzVgwABduHAhz+sYOnSowsLCNG/ePB0/flwTJ07UwYMHs/zv5bCwMHXu3FnVqlVL8+rTp4+uXr2q7777To0bN1ajRo3UqVMnRURE6NSpU/r++++1du1aSdKYMWO0Z88eDRo0SAcPHtSvv/6qWbNm6dKlS5KkJ598UvPnz9f27dv1yy+/qGfPntaJFLJSrlw57d27V+vWrdNvv/2mcePGac+ePWm2GT9+vKZMmaLp06fr+PHj+vnnn/Xxxx+n2aZfv36aN2+ejh49qp49e+b0Z31gELTJcgVY6lVtM2ZYbovMa/HxlivqpJxPgpCZkBDLhAiS5fv98sv9j7lihTRqlGV56lRLKAgAAAAAwINu3Lhxql27tlq2bKkmTZrI399fHTp0yPM6nn/+eY0ZM0avvfaaateurVOnTqlXr17y8PDIcPt9+/bpwIED6tSpU7rPvL291aJFC4WFhUmSli9frjp16ui5555TlSpVNHLkSOusohUqVND69et14MABPfbYY6pXr56++eYb6zPfxowZo0aNGqlt27Zq3bq1OnTooLJly971+wwcOFAdO3ZU165dVbduXV2+fDndM+h69uypadOmaebMmapataratm2b7mrCp556SgEBAWrZsmWWM7o+6Ezmu90I7GDi4uJUoEABXbp0Sb6+vtb1CQlSUJB08aK0cKHl2WZ5ae5cqXdvqVQp6cQJy9ViRkhJsUyqsHatVLWqtHu35HWPd27u2SM1bizdumW5dfTjjy0hpa0lJSVpzZo1at26dbp752F/6KdjoZ+OhX46HnrqWOinY6GfjuVB7uft27d16tQplS5dOtOgB+mlpKQoLi5OPj4+cjLgP+CbN28uf39/zZ8/34Dq7FN8fLyKFSum8PDwdLPFGiGrv+uXL19W4cKFde3aNfn4+NzXcbii7X/c3S3hkSR9+KGxzzTLjtRbOwcMMC5kkyxjzZsn+flJhw9LI0bc2zhnzliuXrt1SwoNlaZNezBCNgAAAAAA7El8fLymTp2qw4cP69dff9Vbb72lDRs22PXtkvcjJSVF0dHRGjdunAoUKKCnn37a1iXdF4K2vxk40BK47d0r7diRd8eNjJR+/NHyPLXceN5f0aJSaij+2WfS8uU52//aNcvMrBcvSjVqSEuW3PuMqAAAAAAAPMxMJpPWrFmjhg0bKjg4WKtXr9by5cv11FNP2bo0m4iKilLx4sX11VdfKTw83Horq72y7+oNVqSI1KOH9PnnlqvaGjTIm+OmXs3WsaPlyrPc0Ly55dlq//d/lllIQ0Ist8rezZ07Uteulue7BQRYZhj19s6dGgEAAAAAcHSenp7asGGDrct4YJQqVUqO9FQzrmj7h+HDLX9+/bWUjVls79v169KCBZZloyZByMx//iPVrStdvWp5Bt2dO1lvbzZLQ4dK69ZZnuu2erUUGJi7NQIAAAAAANgrgrZ/qFpVatHCMonA9Om5f7xFi6QbN6QKFaQmTXL3WK6u0pdfSj4+0s6d0oQJWW8/bZr06aeWZ7EtWiQFB+dufQAAAAAAAPaMoC0Dr7xi+TMsTIqLy73jmM1/3TY6cGDeTC5QurQ0e7Zl+Z13pM2bM97um2+kV1+1LH/wgdS+fe7XBgAAAAAAYM8I2jLQsqVUubLlts6wsNw7zp490v79lgkY8nJyka5dpb59LUHfCy9Ily6l/XzfPsutpWazJQBMDR4BAAAAAACQOYK2DJhMfz2rbfp0KTk5d47z6aeWP7t0kQoVyp1jZOajj6RKlaToaMtMp6nPHTx7VmrXToqPt9xCO3163lxpBwAAAAAAYO8I2jLRo4fk6yudPm2ZGMFoV69KixdblgcONH78u8mXz3J8d3fLTKLTp1uu4GvbVoqJsTyr7quvLM91AwAAAAAAwN0RtGXC0/OvAOzDD40ff/586dYtqXp1qV4948fPjpo1Lc9fk6SRI6XQUOngQcnPT/ruO6lAAdvUBQAAAABAXmjSpImGp97SJqlUqVKaNm1alvuYTCZ9bcAVOUaNgwcLQVsWBg+2XNG1Y4fleWpGMZv/um00ryZByMzgwZaJDhITLd/T01NatUoKCrJdTQAAAAAAZKVdu3Z66qmnMvxs165dMplM+vnnn3M87p49e9S/f//7LS+N8ePHq1atWunWx8TEKDQ01NBjZebWrVsqWLCgChUqpFu3buXJMR9WBG1ZCAiQunWzLBt5VdsPP0hHjlhu33zhBePGvRcmk2XCh5IlLcvz50uPPWbbmgAAAAAAyErfvn21adMmnTlzJt1n4eHhqlWrlmrXrp3jcYsUKSIvLy8jSrwrf39/ubu758mxli9frmrVqqlKlSpasWJFnhwzM2azWXfu3LFpDbmJoO0uUmfcXLpUOnfOmDFTr2Z77jnJx8eYMe+Hr6906JD0++9Sp062rgYAAAAAYEtms3Tzpm1eqRP13U3btm1VtGhRzZ07N836+Ph4LVmyRH379tXly5f13HPPqUSJEvLy8lL16tX15ZdfZjnuP28dPX78uBo1aiQPDw9VqVJFERER6fYZNWqUKlSoIC8vL5UpU0bjxo1TUlKSJGnu3LmaMGGCDhw4IJPJJJPJZK35n7eOHjp0SE8++aQ8PT3l6+ur/v3768aNG9bPe/XqpQ4dOuiDDz5QQECAfH19NXjwYOuxshIWFqYXXnhBL7zwgsLCwtJ9fvjwYbVp00Y+Pj7y9vZWw4YNdeLECevn4eHhqlq1qtzd3RUQEKAhQ4ZIkk6fPi2TyaTIyEjrtlevXpXJZNKWLVskSVu2bJHJZNK6desUEhIid3d3bd++XSdOnFD79u3l5+en/Pnzq06dOtqwYUOauhISEjRy5EgFBgbK3d1d5cuXV1hYmMxms8qVK6cPUp+H9T+//PKLnJyc0tSe11xsdmQ78eijUuPG0tat0owZ0uTJ9zfepUvSsmWWZVtMgpAZH58HI/QDAAAAANhWfLyUP79tjn3jhuXur7txcXHRiy++qLlz5+rNN9+U6X/PZFq6dKkSExP1/PPPKz4+XsHBwRo1apR8fHz03XffqUePHipTpozq1q1712OkpKSoY8eOKly4sH788UfFxcWleZ5bKm9vb82dO1fFihXToUOH9NJLL8nb21sjR45U165d9csvv2jt2rXWEKlABg9Ej4+PV6tWrfT4449rz549io2NVb9+/TRkyJA0YeLmzZsVEBCgzZs36/fff1fXrl1Vq1YtvfTSS5l+jxMnTmjXrl1asWKFzGazhg8frpMnT6pMmTKSpPPnz6tRo0Zq0qSJNm3aJB8fH+3YscN61dmsWbM0YsQITZ48WaGhobp27Zp27Nhx19/vn0aOHKkPPvhAZcqU0SOPPKJz586pdevWmjhxojw8PDRv3jy1a9dOx44dU8mSJSVJL774onbt2qXp06erZs2aOnXqlC5duiSTyaQ+ffpozpw5eu2116zHCA8PV8OGDVW2bNkc12cUgrZseOUVS9A2e7Y0blz2TvrMzJ1reR5aSIgUHGxYiQAAAAAAPFT69Omj999/X1u2bFHTpk0lWYKWjh07qmDBgipYsGCaEGbo0KFau3atli5dmq2gbcOGDTp69KhOnz6tEiVKSJLefffddM9Ve+ONN6zLpUqV0quvvqolS5Zo5MiR8vT0VP78+eXi4iJ/f/9Mj7Vw4ULdunVLX3zxhfL9L3SYMWOG2rVrp//7v/+Tn5+fJKlgwYKaMWOGnJ2dValSJbVp00YbN27MMmgLDw9XaGioChYsKElq1aqVwsPDNXHiREnSJ598ogIFCmjx4sVydXWVJFWoUMG6/8SJE/Xqq69q2LBh1nV16tS56+/3T2+//baaN29ufe/r66uaNWumOc7KlSu1atUqDRkyRL/99pu++uorRUREWJ/HlxoOSlLv3r315ptvavfu3XrssceUlJSkBQsW6P33389xbUbi1tFsaNtWKltW+vNPad68ex8nJUX67DPL8oN0NRsAAAAAAKm8vCxXltnilZPHo1WqVEn169dXeHi4JMuVW9u3b1efPn0kScnJyXrnnXdUo0YN+fr6Kn/+/Fq/fr2ioqKyNf7Ro0dVsmRJa8gmSfXq1Uu33bJly9SgQQP5+/srf/78GjduXLaP8fdj1axZ0xqySdITTzyhlJQUHTt2zLquatWqcnZ2tr4PCAhQbGxspuMmJydr3rx5euFvD4h/4YUXNG/ePCUnJ0uSIiMj1bBhQ2vI9nexsbGKjo5Ws2bNcvR9MhISEpLm/c2bNzVy5EhVqVJFjzzyiPLnz69ff/3V+ttFRkbK2dlZjRs3znC8gIAAtWnTxtr/b7/9Vrdv39azzz5737XeD4K2bHB2llKD22nTLIHZvdi0yfIcNB+fvyZZAAAAAADgQWIyWe7kssXrf3eAZlvfvn21fPlyxcXFac6cOQoKCrKGQlOmTNGHH36okSNHatOmTYqMjFTLli2VmJiYrbHNGTwwzvSPAn/88Ud169ZNoaGh+vbbb7V//36NHTs228f4+7H+OXZGx/xnGGYymZSSRUixbt06nT9/Xl27dpWLi4tcXFzUrVs3nTt3TuvXr5ckeXp6Zrp/Vp9JkpOTk7X+VJk9M+7vIaIk/fvf/9by5cv1zjvvaPv27YqMjFT16tWtv93dji1J/fr10+LFi3Xr1i3NmTNHXbt2zbPJLDJD0JZNvXtLBQpIx49La9bc2xipkyD06HF/t58CAAAAAACpS5cucnZ21qJFizRv3jz17t3bGkxt375d7du31wsvvKCaNWuqTJkyOn78eLbHrlKliqKiohQdHW1dt2vXrjTb7Ny5U0FBQRo7dqxCQkJUvnz5dDOhurm5Wa8ey+pYkZGRunnzpnXdjh075OTklOY2zpwKCwtTt27dFBkZmeb1/PPPWydFqFGjhrZv355hQObt7a1SpUpp48aNGY5fpEgRSVJMTIx13d8nRsjK9u3b1atXLz3zzDOqXr26/P39dfr0aevn1atXV0pKirZu3ZrpGK1bt1a+fPk0a9Ysff/999arGW2JoC2b8ueXUm95/vDDnO8fEyN9841lecAA4+oCAAAAAOBhlT9/fnXt2lWvv/66oqOj1atXL+tn5cqVU0REhHbu3KmjR49qwIABunDhQrbHfuqpp1SxYkW9+OKLOnDggLZv366xY8em2aZs2bKKiorS4sWLdeLECU2fPl0rV65Ms02pUqV06tQpRUZG6tKlS0pISEh3rOeff14eHh7q2bOnfvnlF23evFlDhw5Vjx49rM9ny6k//vhDq1evVs+ePVWtWrU0r549e2rVqlX6448/NGTIEMXFxalbt27au3evjh8/rvnz51tvWR0/frymTJmi6dOn6/jx4/r555/18ccfS7Jcdfb4449r8uTJOnLkiLZt25bmmXVZKVeunFasWKHIyEgdOHBA3bt3T3N1XqlSpdSzZ0/16dNHX3/9tU6dOqUtW7boq6++sm7j7OysXr16acyYMSpXrlyGt/bmNYK2HBg61HIb6aZN0oEDOds3PFy6c0d64gmpevXcqQ8AAAAAgIdN37599eeff+qpp56yzlYpSePGjVPt2rXVsmVLNWnSRP7+/urQoUO2x3VyctLKlSuVkJCgxx57TP369dM777yTZpv27dvrlVde0ZAhQ1SrVi3t3LlT48aNS7NNp06d1KpVKzVt2lRFihTRl19+me5YXl5eWrduna5cuaI6deqoc+fOatasmWbMmJGzH+NvUidWyOj5ak2bNpW3t7fmz58vX19fbdq0STdu3FDjxo0VHBys//73v9bbVHv27Klp06Zp5syZqlq1qtq2bZvmysDw8HAlJSUpJCREw4YNs06ycDcffvihChYsqPr166tdu3Zq2bKlateunWabWbNmqXPnzho0aJAqVaqkl156Kc1Vf5Kl/4mJiQ/E1WySZDJndNOxA4uLi1OBAgV06dIl+fr65nj/rl2lr76SevWS5szJ3j7JyVKZMlJUlDR/vvS3ZxDCAElJSVqzZo1at26d4cMbYV/op2Ohn46FfjoeeupY6KdjoZ+O5UHu5+3bt3Xq1CmVLl1aHh4eti7HbqSkpCguLk4+Pj7W55TBNnbs2KEmTZro3LlzWV79l9Xf9cuXL6tw4cK6du2afHx87qse/jbk0CuvWP5ctEjK7hWna9daQrZChaTOnXOvNgAAAAAAgIdBQkKCfv/9d40bN05dunS551tsjUbQlkOPP255JSZKs2Zlb5/PPrP82auXxP9BAAAAAAAAcH++/PJLVaxYUdeuXdN7771n63KsCNruQepVbbNmSbdvZ71tVJT03XeW5f79c7cuAAAAAACAh0GvXr2UnJysffv2qXjx4rYux4qg7R507CiVLCn98Ye0cGHW237+uZSSIj35pFSxYt7UBwAAAAAAgLxH0HYPXFwsM5BK0ocfSplNJ5GUZAnaJGngwLypDQAAAACAnHrI5knEQyiv/o4TtN2jfv2kfPmkw4elDRsy3mb1aikmRipaVGrfPm/rAwAAAADgblJnQY2Pj7dxJUDuSv07ntsz/7rk6ugO7JFHpD59pI8/tlzV1rx5+m1SJ0Ho21dyc8vT8gAAAAAAuCtnZ2c98sgjio2NlSR5eXnJZDLZuKoHX0pKihITE3X79m05OXEN04PMbDYrPj5esbGxeuSRR+Ts7JyrxyNouw/DhkkzZkjffy8dPSpVrvzXZydOSOvXSyaT9NJLtqsRAAAAAICs+Pv7S5I1bMPdmc1m3bp1S56engSTduKRRx6x/l3PTQRt96FsWenpp6VvvpE++kj69NO/Pps92/Jnq1ZS6dK2qQ8AAAAAgLsxmUwKCAhQ0aJFlZSUZOty7EJSUpK2bdumRo0a5fqtiLh/rq6uuX4lWyqCtvv0yiuWoO2LL6R33pF8faWEBCk83PI5kyAAAAAAAOyBs7NznoUR9s7Z2Vl37tyRh4cHQRvS4Ebi+9SokfToo9KtW389k23lSunSJal4cal1a9vWBwAAAAAAgLxh86Bt5syZKl26tDw8PBQcHKzt27dnuf0nn3yiypUry9PTUxUrVtQXX3yRR5VmzGSyXNUmWZ7Xlpj41y2kL70kuXDNIAAAAAAAwEPBpkHbkiVLNHz4cI0dO1b79+9Xw4YNFRoaqqioqAy3nzVrlsaMGaPx48fr8OHDmjBhggYPHqzVq1fnceVpde0qBQRIMTHShAnS1q2Ss7PUr59NywIAAAAAAEAesmnQNnXqVPXt21f9+vVT5cqVNW3aNAUGBmrWrFkZbj9//nwNGDBAXbt2VZkyZdStWzf17dtX//d//5fHlafl5iYNHmxZfvddy5/t2lluHQUAAAAAAMDDwWY3NiYmJmrfvn0aPXp0mvUtWrTQzp07M9wnISFBHh4eadZ5enpq9+7dSkpKyvABhAkJCUpISLC+j4uLk2SZIcTI2VT69JEmTnTR7duWaX379bujpCSzYeMjc6l9ZHYcx0A/HQv9dCz00/HQU8dCPx0L/XQs9NPx0FPHYmQfTWaz2SZpUHR0tIoXL64dO3aofv361vXvvvuu5s2bp2PHjqXb5/XXX9ecOXP07bffqnbt2tq3b5/atGmj2NhYRUdHKyAgIN0+48eP14QJE9KtX7Rokby8vAz9TjNn1tT69aXk53dTs2ZtkJPNn4AHAAAAAACArMTHx6t79+66du2afHx87mssmz+q32QypXlvNpvTrUs1btw4XbhwQY8//rjMZrP8/PzUq1cvvffee5lOQTxmzBiNGDHC+j4uLk6BgYFq2rSpfH19jfsikmrVkoYPT1Hfvu5q2ZLpRvNKUlKSIiIi1Lx5c6ZVdgD007HQT8dCPx0PPXUs9NOx0E/HQj8dDz11LJcvXzZsLJsFbYULF5azs7MuXLiQZn1sbKz8/Pwy3MfT01Ph4eH67LPPdPHiRQUEBGj27Nny9vZW4cKFM9zH3d1d7u7u6da7uroafjIEBUkrV0oPwGSuD6Xc6Clsh346FvrpWOin46GnjoV+Ohb66Vjop+Ohp47ByB7aLBFyc3NTcHCwIiIi0qyPiIhIcytpRlxdXVWiRAk5Oztr8eLFatu2rZy4TxMAAAAAAAA2ZNNbR0eMGKEePXooJCRE9erV0+zZsxUVFaWBAwdKstz2ef78eX3xxReSpN9++027d+9W3bp19eeff2rq1Kn65ZdfNG/ePFt+DQAAAAAAAMC2QVvXrl11+fJlvf3224qJiVG1atW0Zs0aBQUFSZJiYmIUFRVl3T45OVlTpkzRsWPH5OrqqqZNm2rnzp0qVaqUjb4BAAAAAAAAYGHzyRAGDRqkQYMGZfjZ3Llz07yvXLmy9u/fnwdVAQAAAAAAADnDg80AAAAAAAAAAxC0AQAAAAAAAAYgaAMAAAAAAAAMQNAGAAAAAAAAGICgDQAAAAAAADAAQRsAAAAAAABgAII2AAAAAAAAwAAEbQAAAAAAAIABCNoAAAAAAAAAAxC0AQAAAAAAAAYgaAMAAAAAAAAMQNAGAAAAAAAAGICgDQAAAAAAADAAQRsAAAAAAABgAII2AAAAAAAAwAAEbQAAAAAAAIABCNoAAAAAAAAAAxC0AQAAAAAAAAYgaAMAAAAAAAAMQNAGAAAAAAAAGICgDQAAAAAAADAAQRsAAAAAAABgAII2AAAAAAAAwAAEbQAAAAAAAIABCNoAAAAAAAAAAxC0AQAAAAAAAAYgaAMAAAAAAAAMQNAGAAAAAAAAGICgDQAAAAAAADAAQRsAAAAAAABgAII2AAAAAAAAwAAEbQAAAAAAAIABCNoAAAAAAAAAAxC0AQAAAAAAAAYgaAMAAAAAAAAMQNAGAAAAAAAAGICgDQAAAAAAADAAQRsAAAAAAABgAII2AAAAAAAAwAAEbQAAAAAAAIABCNoAAAAAAAAAAxC0AQAAAAAAAAYgaAMAAAAAAAAMQNAGAAAAAAAAGICgDQAAAAAAADAAQRsAAAAAAABgAII2AAAAAAAAwAAEbQAAAAAAAIABCNoAAAAAAAAAAxC0AQAAAAAAAAYgaAMAAAAAAAAMYPOgbebMmSpdurQ8PDwUHBys7du3Z7n9woULVbNmTXl5eSkgIEC9e/fW5cuX86haAAAAAAAAIGM2DdqWLFmi4cOHa+zYsdq/f78aNmyo0NBQRUVFZbj9Dz/8oBdffFF9+/bV4cOHtXTpUu3Zs0f9+vXL48oBAAAAAACAtGwatE2dOlV9+/ZVv379VLlyZU2bNk2BgYGaNWtWhtv/+OOPKlWqlF5++WWVLl1aDRo00IABA7R37948rhwAAAAAAABIy8VWB05MTNS+ffs0evToNOtbtGihnTt3ZrhP/fr1NXbsWK1Zs0ahoaGKjY3VsmXL1KZNm0yPk5CQoISEBOv7uLg4SVJSUpKSkpIM+CawtdQ+0k/HQD8dC/10LPTT8dBTx0I/HQv9dCz00/HQU8diZB9NZrPZbNhoORAdHa3ixYtrx44dql+/vnX9u+++q3nz5unYsWMZ7rds2TL17t1bt2/f1p07d/T0009r2bJlcnV1zXD78ePHa8KECenWL1q0SF5eXsZ8GQAAAAAAANil+Ph4de/eXdeuXZOPj899jWWzK9pSmUymNO/NZnO6damOHDmil19+WW+++aZatmypmJgY/fvf/9bAgQMVFhaW4T5jxozRiBEjrO/j4uIUGBiopk2bytfX17gvAptJSkpSRESEmjdvnmngCvtBPx0L/XQs9NPx0FPHQj8dC/10LPTT8dBTx2LkJJs5DtpKlSqlPn36qFevXipZsuQ9H7hw4cJydnbWhQsX0qyPjY2Vn59fhvtMmjRJTzzxhP79739LkmrUqKF8+fKpYcOGmjhxogICAtLt4+7uLnd393TrXV1dORkcDD11LPTTsdBPx0I/HQ89dSz007HQT8dCPx0PPXUMRvYwx5MhvPrqq/rmm29UpkwZNW/eXIsXL07zDLTscnNzU3BwsCIiItKsj4iISHMr6d/Fx8fLySltyc7OzpIsV8IBAAAAAAAAtpLjoG3o0KHat2+f9u3bpypVqujll19WQECAhgwZop9//jlHY40YMUKff/65wsPDdfToUb3yyiuKiorSwIEDJVlu+3zxxRet27dr104rVqzQrFmzdPLkSe3YsUMvv/yyHnvsMRUrViynXwUAAAAAAAAwTI6DtlQ1a9bURx99pPPnz+utt97S559/rjp16qhmzZoKDw/P1hVmXbt21bRp0/T222+rVq1a2rZtm9asWaOgoCBJUkxMjKKioqzb9+rVS1OnTtWMGTNUrVo1Pfvss6pYsaJWrFhxr18DAAAAAAAAMMQ9T4aQlJSklStXas6cOYqIiNDjjz+uvn37Kjo6WmPHjtWGDRu0aNGiu44zaNAgDRo0KMPP5s6dm27d0KFDNXTo0HstGwAAAAAAAMgVOQ7afv75Z82ZM0dffvmlnJ2d1aNHD3344YeqVKmSdZsWLVqoUaNGhhYKAAAAAAAAPMhyHLTVqVNHzZs316xZs9ShQ4cMZ2aoUqWKunXrZkiBAAAAAAAAgD3IcdB28uRJ6zPUMpMvXz7NmTPnnosCAAAAAAAA7E2OJ0OIjY3VTz/9lG79Tz/9pL179xpSFAAAAAAAAGBvchy0DR48WGfPnk23/vz58xo8eLAhRQEAAAAAAAD2JsdB25EjR1S7du106x999FEdOXLEkKIAAAAAAAAAe5PjoM3d3V0XL15Mtz4mJkYuLjl+5BsAAAAAAADgEHIctDVv3lxjxozRtWvXrOuuXr2q119/Xc2bNze0OAAAAAAAAMBe5PgStClTpqhRo0YKCgrSo48+KkmKjIyUn5+f5s+fb3iBAAAAAAAAgD3IcdBWvHhxHTx4UAsXLtSBAwfk6emp3r1767nnnpOrq2tu1AgAAAAAAAA88O7poWr58uVT//79ja4FAAAAAAAAsFv3PHvBkSNHFBUVpcTExDTrn3766fsuCgAAAAAAALA3OQ7aTp48qWeeeUaHDh2SyWSS2WyWJJlMJklScnKysRUCAAAAAAAAdiDHs44OGzZMpUuX1sWLF+Xl5aXDhw9r27ZtCgkJ0ZYtW3KhRAAAAAAAAODBl+Mr2nbt2qVNmzapSJEicnJykpOTkxo0aKBJkybp5Zdf1v79+3OjTgAAAAAAAOCBluMr2pKTk5U/f35JUuHChRUdHS1JCgoK0rFjx4ytDgAAAAAAALATOb6irVq1ajp48KDKlCmjunXr6r333pObm5tmz56tMmXK5EaNAAAAAAAAwAMvx0HbG2+8oZs3b0qSJk6cqLZt26phw4by9fXVkiVLDC8QAAAAAAAAsAc5DtpatmxpXS5TpoyOHDmiK1euqGDBgtaZRwEAAAAAAICHTY6e0Xbnzh25uLjol19+SbO+UKFChGwAAAAAAAB4qOUoaHNxcVFQUJCSk5Nzqx4AAAAAAADALuV41tE33nhDY8aM0ZUrV3KjHgAAAAAAAMAu5fgZbdOnT9fvv/+uYsWKKSgoSPny5Uvz+c8//2xYcQAAAAAAAIC9yHHQ1qFDh1woAwAAAAAAALBvOQ7a3nrrrdyoAwAAAAAAALBrOX5GGwAAAAAAAID0cnxFm5OTk0wmU6afMyMpAAAAAAAAHkY5DtpWrlyZ5n1SUpL279+vefPmacKECYYVBgAAAAAAANiTHAdt7du3T7euc+fOqlq1qpYsWaK+ffsaUhgAAAAAAABgTwx7RlvdunW1YcMGo4YDAAAAAAAA7IohQdutW7f08ccfq0SJEkYMBwAAAAAAANidHN86WrBgwTSTIZjNZl2/fl1eXl5asGCBocUBAAAAAAAA9iLHQduHH36YJmhzcnJSkSJFVLduXRUsWNDQ4gAAAAAAAAB7keOgrVevXrlQBgAAAAAAAGDfcvyMtjlz5mjp0qXp1i9dulTz5s0zpCgAAAAAAADA3uQ4aJs8ebIKFy6cbn3RokX17rvvGlIUAAAAAAAAYG9yHLSdOXNGpUuXTrc+KChIUVFRhhQFAAAAAAAA2JscB21FixbVwYMH060/cOCAfH19DSkKAAAAAAAAsDc5Dtq6deuml19+WZs3b1ZycrKSk5O1adMmDRs2TN26dcuNGgEAAAAAAIAHXo5nHZ04caLOnDmjZs2aycXFsntKSopefPFFntEGAAAAAACAh1aOgzY3NzctWbJEEydOVGRkpDw9PVW9enUFBQXlRn0AAAAAAACAXchx0JaqfPnyKl++vJG1AAAAAAAAAHYrx89o69y5syZPnpxu/fvvv69nn33WkKIAAAAAAAAAe5PjoG3r1q1q06ZNuvWtWrXStm3bDCkKAAAAAAAAsDc5Dtpu3LghNze3dOtdXV0VFxdnSFEAAAAAAACAvclx0FatWjUtWbIk3frFixerSpUqhhQFAAAAAAAA2JscT4Ywbtw4derUSSdOnNCTTz4pSdq4caMWLVqkZcuWGV4gAAAAAAAAYA9yHLQ9/fTT+vrrr/Xuu+9q2bJl8vT0VM2aNbVp0yb5+PjkRo0AAAAAAADAAy/HQZsktWnTxjohwtWrV7Vw4UINHz5cBw4cUHJysqEFAgAAAAAAAPYgx89oS7Vp0ya98MILKlasmGbMmKHWrVtr7969RtYGAAAAAAAA2I0cXdF27tw5zZ07V+Hh4bp586a6dOmipKQkLV++nIkQAAAAAAAA8FDL9hVtrVu3VpUqVXTkyBF9/PHHio6O1scff3zfBcycOVOlS5eWh4eHgoODtX379ky37dWrl0wmU7pX1apV77sOAAAAAAAA4H5kO2hbv369+vXrpwkTJqhNmzZydna+74MvWbJEw4cP19ixY7V//341bNhQoaGhioqKynD7jz76SDExMdbX2bNnVahQIT377LP3XQsAAAAAAABwP7IdtG3fvl3Xr19XSEiI6tatqxkzZuiPP/64r4NPnTpVffv2Vb9+/VS5cmVNmzZNgYGBmjVrVobbFyhQQP7+/tbX3r179eeff6p37973VQcAAAAAAABwv7L9jLZ69eqpXr16+uijj7R48WKFh4drxIgRSklJUUREhAIDA+Xt7Z3tAycmJmrfvn0aPXp0mvUtWrTQzp07szVGWFiYnnrqKQUFBWW6TUJCghISEqzv4+LiJElJSUlKSkrKdr14cKX2kX46BvrpWOinY6GfjoeeOhb66Vjop2Ohn46HnjoWI/toMpvN5nvd+dixYwoLC9P8+fN19epVNW/eXKtWrcrWvtHR0SpevLh27Nih+vXrW9e/++67mjdvno4dO5bl/jExMQoMDNSiRYvUpUuXTLcbP368JkyYkG79okWL5OXlla1aAQAAAAAA4Jji4+PVvXt3Xbt2TT4+Pvc1Vo5mHf2nihUr6r333tOkSZO0evVqhYeH53gMk8mU5r3ZbE63LiNz587VI488og4dOmS53ZgxYzRixAjr+7i4OAUGBqpp06by9fXNcb148CQlJSkiIkLNmzeXq6urrcvBfaKfjoV+Ohb66XjoqWOhn46FfjoW+ul46KljuXz5smFj3VfQlsrZ2VkdOnS4a+j1d4ULF5azs7MuXLiQZn1sbKz8/Pyy3NdsNis8PFw9evSQm5tbltu6u7vL3d093XpXV1dOBgdDTx0L/XQs9NOx0E/HQ08dC/10LPTTsdBPx0NPHYORPcz2ZAhGc3NzU3BwsCIiItKsj4iISHMraUa2bt2q33//XX379s3NEgEAAAAAAIBsM+SKtns1YsQI9ejRQyEhIapXr55mz56tqKgoDRw4UJLlts/z58/riy++SLNfWFiY6tatq2rVqtmibAAAAAAAACAdmwZtXbt21eXLl/X2228rJiZG1apV05o1a6yziMbExCgqKirNPteuXdPy5cv10Ucf2aJkAAAAAAAAIEM2DdokadCgQRo0aFCGn82dOzfdugIFCig+Pj6XqwIAAAAAAAByxmbPaAMAAAAAAAAcCUEbAAAAAAAAYACCNgAAAAAAAMAABG0AAAAAAACAAQjaAAAAAAAAAAMQtAEAAAAAAAAGIGgDAAAAAAAADEDQBgAAAAAAABiAoA0AAAAAAAAwAEEbAAAAAAAAYACCNgAAAAAAAMAABG0AAAAAAACAAQjaAAAAAAAAAAMQtAEAAAAAAAAGIGgDAAAAAAAADEDQBgAAAAAAABiAoA0AAAAAAAAwAEEbAAAAAAAAYACCNgAAAAAAAMAABG0AAAAAAACAAQjaAAAAAAAAAAMQtAEAAAAAAAAGIGgDAAAAAAAADEDQBgAAAAAAABiAoA0AAAAAAAAwAEEbAAAAAAAAYACCNgAAAAAAAMAABG0AAAAAAACAAQjaAAAAAAAAAAMQtAEAAAAAAAAGIGgDAAAAAAAADEDQBgAAAAAAABiAoA0AAAAAAAAwAEEbAAAAAAAAYACCNgAAAAAAAMAABG0AAAAAAACAAQjaAAAAAAAAAAMQtAEAAAAAAAAGIGgDAAAAAAAADEDQBgAAAAAAABiAoA0AAAAAAAAwAEEbAAAAAAAAYACCNgAAAAAAAMAABG0AAAAAAACAAQjaAAAAAAAAAAMQtAEAAAAAAAAGIGgDAAAAAAAADEDQBgAAAAAAABiAoA0AAAAAAAAwAEEbAAAAAAAAYACbB20zZ85U6dKl5eHhoeDgYG3fvj3L7RMSEjR27FgFBQXJ3d1dZcuWVXh4eB5VCwAAAAAAAGTMxZYHX7JkiYYPH66ZM2fqiSee0GeffabQ0FAdOXJEJUuWzHCfLl266OLFiwoLC1O5cuUUGxurO3fu5HHlAAAAAAAAQFo2DdqmTp2qvn37ql+/fpKkadOmad26dZo1a5YmTZqUbvu1a9dq69atOnnypAoVKiRJKlWqVF6WDAAAAAAAAGTIZkFbYmKi9u3bp9GjR6dZ36JFC+3cuTPDfVatWqWQkBC99957mj9/vvLly6enn35a//nPf+Tp6ZnhPgkJCUpISLC+j4uLkyQlJSUpKSnJoG8DW0rtI/10DPTTsdBPx0I/HQ89dSz007HQT8dCPx0PPXUsRvbRZkHbpUuXlJycLD8/vzTr/fz8dOHChQz3OXnypH744Qd5eHho5cqVunTpkgYNGqQrV65k+py2SZMmacKECenWb968WV5eXvf/RfDAiIiIsHUJMBD9dCz007HQT8dDTx0L/XQs9NOx0E/HQ08dQ3x8vGFj2fTWUUkymUxp3pvN5nTrUqWkpMhkMmnhwoUqUKCAJMvtp507d9Ynn3yS4VVtY8aM0YgRI6zv4+LiFBgYqKZNm8rX19fAbwJbSUpKUkREhJo3by5XV1dbl4P7RD8dC/10LPTT8dBTx0I/HQv9dCz00/HQU8dy+fJlw8ayWdBWuHBhOTs7p7t6LTY2Nt1VbqkCAgJUvHhxa8gmSZUrV5bZbNa5c+dUvnz5dPu4u7vL3d093XpXV1dOBgdDTx0L/XQs9NOx0E/HQ08dC/10LPTTsdBPx0NPHYORPXQybKQccnNzU3BwcLrLLCMiIlS/fv0M93niiScUHR2tGzduWNf99ttvcnJyUokSJXK1XgAAAAAAACArNgvaJGnEiBH6/PPPFR4erqNHj+qVV15RVFSUBg4cKMly2+eLL75o3b579+7y9fVV7969deTIEW3btk3//ve/1adPn0wnQwAAAAAAAADygk2f0da1a1ddvnxZb7/9tmJiYlStWjWtWbNGQUFBkqSYmBhFRUVZt8+fP78iIiI0dOhQhYSEyNfXV126dNHEiRNt9RUAAAAAAAAASQ/AZAiDBg3SoEGDMvxs7ty56dZVqlSJWT0AAAAAAADwwLHpraMAAAAAAACAoyBoAwAAAAAAAAxA0AYAAAAAAAAYgKANAAAAAAAAMABBGwAAAAAAAGAAgjYAAAAAAADAAARtAAAAAAAAgAEI2gAAAAAAAAADELQBAAAAAAAABiBoAwAAAAAAAAxA0AYAAAAAAAAYgKANAAAAAAAAMABBGwAAAAAAAGAAgjYAAAAAAADAAARtAAAAAAAAgAEI2gAAAAAAAAADELQBAAAAAAAABiBoAwAAAAAAAAxA0AYAAAAAAAAYgKANAAAAAAAAMABBGwAAAAAAAGAAgjYAAAAAAADAAARtAAAAAAAAgAEI2gAAAAAAAAADELQBAAAAAAAABiBoAwAAAAAAAAxA0AYAAAAAAAAYgKANAAAAAAAAMABBGwAAAAAAAGAAgjYAAAAAAADAAARtAAAAAAAAgAEI2gAAAAAAAAADELQBAAAAAAAABiBoAwAAAAAAAAxA0AYAAAAAAAAYgKANAAAAAAAAMABBGwAAAAAAAGAAgjYAAAAAAADAAARtAAAAAAAAgAEI2gAAAAAAAAADELQBAAAAAAAABiBoAwAAAAAAAAxA0AYAAAAAAAAYgKANAAAAAAAAMABBGwAAAAAAAGAAgjYAAAAAAADAAARtAAAAAAAAgAEI2gAAAAAAAAADELQBAAAAAAAABiBoAwAAAAAAAAxA0AYAAAAAAAAYwOZB28yZM1W6dGl5eHgoODhY27dvz3TbLVu2yGQypXv9+uuveVgxAAAAAAAAkJ5Ng7YlS5Zo+PDhGjt2rPbv36+GDRsqNDRUUVFRWe537NgxxcTEWF/ly5fPo4oBAAAAAACAjNk0aJs6dar69u2rfv36qXLlypo2bZoCAwM1a9asLPcrWrSo/P39rS9nZ+c8qhgAAAAAAADImIutDpyYmKh9+/Zp9OjRada3aNFCO3fuzHLfRx99VLdv31aVKlX0xhtvqGnTpplum5CQoISEBOv7a9euSZKuXLlyH9XjQZKUlKT4+HhdvnxZrq6uti4H94l+Ohb66Vjop+Ohp46FfjoW+ulY6KfjoaeOJTUjMpvN9z2WzYK2S5cuKTk5WX5+fmnW+/n56cKFCxnuExAQoNmzZys4OFgJCQmaP3++mjVrpi1btqhRo0YZ7jNp0iRNmDAh3foKFSrc/5cAAAAAAACAQ7h8+bIKFChwX2PYLGhLZTKZ0rw3m83p1qWqWLGiKlasaH1fr149nT17Vh988EGmQduYMWM0YsQI6/urV68qKChIUVFR9/3jZaZOnTras2cPY+fR2HFxcQoMDNTZs2fl4+Nj+Pj2+rvk5ti5OT79tM349DPvx7fHsXO7n5J9/i72PLY9n6P2OnZujk8/bTM+/cz78e1xbP4d6nhj2/M5aq9j5+b4165dU8mSJVWoUKH7HstmQVvhwoXl7Oyc7uq12NjYdFe5ZeXxxx/XggULMv3c3d1d7u7u6dYXKFAg1/4B5+zszNh5OHYqHx+fXDmGvf4uuf2b5/b49DNvx6efeT++vY4t5V4/Jfv9Xex17FT2eI7a69h5MT79zNvx6Wfej2+vY0v8O9SRxk5lj+eovY6dF+M7Od3/VAY2mwzBzc1NwcHBioiISLM+IiJC9evXz/Y4+/fvV0BAgNHl3ZfBgwczdh6Ondvs9XfJ7d/cXnvKb573Y+cmfvO8Hzu32evvYq9j5zZ7/V3s+Z8tuYnfPO/Hzk385nk/dm6z19/FXsfObfb6u9jzP1uMYjIb8aS3e7RkyRL16NFDn376qerVq6fZs2frv//9rw4fPqygoCCNGTNG58+f1xdffCFJmjZtmkqVKqWqVasqMTFRCxYs0OTJk7V8+XJ17NgxW8eMi4tTgQIFdO3atVxPtpE36KljoZ+OhX46FvrpeOipY6GfjoV+Ohb66XjoqWMxsp82fUZb165ddfnyZb399tuKiYlRtWrVtGbNGgUFBUmSYmJiFBUVZd0+MTFRr732ms6fPy9PT09VrVpV3333nVq3bp3tY7q7u+utt97K8HZS2Cd66ljop2Ohn46FfjoeeupY6KdjoZ+OhX46HnrqWIzsp02vaAMAAAAAAAAchc2e0QYAAAAAAAA4EoI2AAAAAAAAwAAEbQAAAAAAAIABCNoAAAAAAAAAAzx0QdvMmTNVunRpeXh4KDg4WNu3b7d1SbgH48ePl8lkSvPy9/e3dVnIgW3btqldu3YqVqyYTCaTvv766zSfm81mjR8/XsWKFZOnp6eaNGmiw4cP26ZY3NXd+tmrV6905+zjjz9um2JxV5MmTVKdOnXk7e2tokWLqkOHDjp27FiabThH7Ud2+sk5aj9mzZqlGjVqyMfHRz4+PqpXr56+//576+ecm/blbv3k3LRvkyZNkslk0vDhw63rOEftV0b95By1L3fLEYw6Px+qoG3JkiUaPny4xo4dq/3796thw4YKDQ1VVFSUrUvDPahatapiYmKsr0OHDtm6JOTAzZs3VbNmTc2YMSPDz9977z1NnTpVM2bM0J49e+Tv76/mzZvr+vXreVwpsuNu/ZSkVq1apTln16xZk4cVIie2bt2qwYMH68cff1RERITu3LmjFi1a6ObNm9ZtOEftR3b6KXGO2osSJUpo8uTJ2rt3r/bu3asnn3xS7du3t/6HAOemfblbPyXOTXu1Z88ezZ49WzVq1EiznnPUPmXWT4lz1N5klSMYdn6aHyKPPfaYeeDAgWnWVapUyTx69GgbVYR79dZbb5lr1qxp6zJgEEnmlStXWt+npKSY/f39zZMnT7auu337trlAgQLmTz/91AYVIif+2U+z2Wzu2bOnuX379japB/cvNjbWLMm8detWs9nMOWrv/tlPs5lz1N4VLFjQ/Pnnn3NuOojUfprNnJv26vr16+by5cubIyIizI0bNzYPGzbMbDbz7097lVk/zWbOUXuTVY5g5Pn50FzRlpiYqH379qlFixZp1rdo0UI7d+60UVW4H8ePH1exYsVUunRpdevWTSdPnrR1STDIqVOndOHChTTnq7u7uxo3bsz5ase2bNmiokWLqkKFCnrppZcUGxtr65KQTdeuXZMkFSpUSBLnqL37Zz9TcY7an+TkZC1evFg3b95UvXr1ODft3D/7mYpz0/4MHjxYbdq00VNPPZVmPeeofcqsn6k4R+1LZjmCkeeni6EVP8AuXbqk5ORk+fn5pVnv5+enCxcu2Kgq3Ku6devqiy++UIUKFXTx4kVNnDhR9evX1+HDh+Xr62vr8nCfUs/JjM7XM2fO2KIk3KfQ0FA9++yzCgoK0qlTpzRu3Dg9+eST2rdvn9zd3W1dHrJgNps1YsQINWjQQNWqVZPEOWrPMuqnxDlqbw4dOqR69erp9u3byp8/v1auXKkqVapY/0OAc9O+ZNZPiXPTHi1evFg///yz9uzZk+4z/v1pf7Lqp8Q5am+yyhGMPD8fmqAtlclkSvPebDanW4cHX2hoqHW5evXqqlevnsqWLat58+ZpxIgRNqwMRuJ8dRxdu3a1LlerVk0hISEKCgrSd999p44dO9qwMtzNkCFDdPDgQf3www/pPuMctT+Z9ZNz1L5UrFhRkZGRunr1qpYvX66ePXtq69at1s85N+1LZv2sUqUK56adOXv2rIYNG6b169fLw8Mj0+04R+1DdvrJOWpfssoRUiexMOL8fGhuHS1cuLCcnZ3TXb0WGxubLrGE/cmXL5+qV6+u48eP27oUGCB15hfOV8cVEBCgoKAgztkH3NChQ7Vq1Spt3rxZJUqUsK7nHLVPmfUzI5yjDzY3NzeVK1dOISEhmjRpkmrWrKmPPvqIc9NOZdbPjHBuPtj27dun2NhYBQcHy8XFRS4uLtq6daumT58uFxcX63nIOWof7tbP5OTkdPtwjtqXv+cIRv479KEJ2tzc3BQcHKyIiIg06yMiIlS/fn0bVQWjJCQk6OjRowoICLB1KTBA6dKl5e/vn+Z8TUxM1NatWzlfHcTly5d19uxZztkHlNls1pAhQ7RixQpt2rRJpUuXTvM556h9uVs/M8I5al/MZrMSEhI4Nx1Eaj8zwrn5YGvWrJkOHTqkyMhI6yskJETPP/+8IiMjVaZMGc5RO3K3fjo7O6fbh3PUvvw9RzDy36EP1a2jI0aMUI8ePRQSEqJ69epp9uzZioqK0sCBA21dGnLotddeU7t27VSyZEnFxsZq4sSJiouLU8+ePW1dGrLpxo0b+v33363vT506pcjISBUqVEglS5bU8OHD9e6776p8+fIqX7683n33XXl5eal79+42rBqZyaqfhQoV0vjx49WpUycFBATo9OnTev3111W4cGE988wzNqwamRk8eLAWLVqkb775Rt7e3tb/Z69AgQLy9PSUyWTiHLUjd+vnjRs3OEftyOuvv67Q0FAFBgbq+vXrWrx4sbZs2aK1a9dybtqhrPrJuWl/vL290zz/UrJcMePr62tdzzlqP+7WT85R+5NVjmDov0NzOh2qvfvkk0/MQUFBZjc3N3Pt2rXTTG0P+9G1a1dzQECA2dXV1VysWDFzx44dzYcPH7Z1WciBzZs3myWle/Xs2dNsNlumV37rrbfM/v7+Znd3d3OjRo3Mhw4dsm3RyFRW/YyPjze3aNHCXKRIEbOrq6u5ZMmS5p49e5qjoqJsXTYykVEvJZnnzJlj3YZz1H7crZ+co/alT58+1v8tW6RIEXOzZs3M69evt37OuWlfsuon56ZjaNy4sXnYsGHW95yj9u3v/eQctT93yxGMOj9NZrPZfL+pIAAAAAAAAPCwe2ie0QYAAAAAAADkJoI2AAAAAAAAwAAEbQAAAAAAAIABCNoAAAAAAAAAAxC0AQAAAAAAAAYgaAMAAAAAAAAMQNAGAAAAAAAAGICgDQAAAAAAADAAQRsAAAByxGQy6euvv7Z1GQAAAA8cgjYAAAA70qtXL5lMpnSvVq1a2bo0AACAh56LrQsAAABAzrRq1Upz5sxJs87d3d1G1QAAACAVV7QBAADYGXd3d/n7+6d5FSxYUJLlts5Zs2YpNDRUnp6eKl26tJYuXZpm/0OHDunJJ5+Up6enfH191b9/f924cSPNNuHh4apatarc3d0VEBCgIUOGpPn80qVLeuaZZ+Tl5aXy5ctr1apVufulAQAA7ABBGwAAgIMZN26cOnXqpAMHDuiFF17Qc889p6NHj0qS4uPj1apVKxUsWFB79uzR0qVLtWHDhjRB2qxZszR48GD1799fhw4d0qpVq1SuXLk0x5gwYYK6dOmigwcPqnXr1nr++ed15cqVPP2eAAAADxqT2Ww227oIAAAAZE+vXr20YMECeXh4pFk/atQojRs3TiaTSQMHDtSsWbOsnz3++OOqXbu2Zs6cqf/+978aNWqUzp49q3z58kmS1qxZo3bt2ik6Olp+fn4qXry4evfurYkTJ2ZYg8lk0htvvKH//Oc/kqSbN2/K29tba9as4VlxAADgocYz2gAAAOxM06ZN0wRpklSoUCHrcr169dJ8Vq9ePUVGRkqSjh49qpo1a1pDNkl64oknlJKSomPHjslkMik6OlrNmjXLsoYaNWpYl/Plyydvb2/Fxsbe61cCAABwCARtAAAAdiZfvnzpbuW8G5PJJEkym83W5Yy28fT0zNZ4rq6u6fZNSUnJUU0AAACOhme0AQAAOJgff/wx3ftKlSpJkqpUqaLIyEjdvHnT+vmOHTvk5OSkChUqyNvbW6VKldLGjRvztGYAAABHwBVtAAAAdiYhIUEXLlxIs87FxUWFCxeWJC1dulQhISFq0KCBFi5cqN27dyssLEyS9Pzzz+utt95Sz549NX78eP3xxx8aOnSoevToIT8/P0nS+PHjNXDgQBUtWlShoaG6fv26duzYoaFDh+btFwUAALAzBG0AAAB2Zu3atQoICEizrmLFivr1118lWWYEXbx4sQYNGiR/f38tXLhQVapUkSR5eXlp3bp1GjZsmOrUqSMvLy916tRJU6dOtY7Vs2dP3b59Wx9++KFee+01FS5cWJ07d867LwgAAGCnmHUUAADAgZhMJq1cuVIdOnSwdSkAAAAPHZ7RBgAAAAAAABiAoA0AAAAAAAAwAM9oAwAAcCA8FQQAAMB2uKINAAAAAAAAMABBGwAAAAAAAGAAgjYAAAAAAADAAARtAAAAAAAAgAEI2gAAAAAAAAADELQBAAAAAAAABiBoAwAAAAAAAAxA0AYAAAAAAAAY4P8Bqs5aAS/xVkQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve training results.\n",
    "train_loss = qat_results.history[\"loss\"]\n",
    "train_acc  = qat_results.history[\"accuracy\"]\n",
    "valid_loss = qat_results.history[\"val_loss\"]\n",
    "valid_acc  = qat_results.history[\"val_accuracy\"]\n",
    "    \n",
    "plot_results([ train_acc, valid_acc ], \n",
    "            ylabel=\"Accuracy\",\n",
    "            ylim = [0.5, 1.0],\n",
    "            metric_name=[\"Training Accuracy\", \"Validation Accuracy\"],\n",
    "            color=[\"g\", \"b\"])\n",
    " \n",
    "max_loss = 2.0\n",
    "\n",
    "plot_results([ train_loss, valid_loss ],        \n",
    "            ylabel=\"Loss\", \n",
    "            ylim = [0.0, max_loss],\n",
    "            metric_name=[\"Training Loss\", \"Validation Loss\"],\n",
    "            color=[\"g\", \"b\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6056f1",
   "metadata": {},
   "source": [
    "**Evaluate quantized model**\n",
    "\n",
    "In order to evaluate the quantized model, it needs to be re-compiled with the desired loss and evaluation metrics, such as accuracy. Since we are using 8-bit quantization we do not lose much performance, if at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64fa03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "deea99d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 39s 178ms/step - loss: 11.7582 - accuracy: 0.0345\n",
      "Model evaluation accuracy (training dataset): 3.448\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation accuracy (training dataset): {qat_model.evaluate(train_dataset)[1]*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b2f681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 33s 178ms/step - loss: 1.8492e-05 - accuracy: 1.0000\n",
      "Model evaluation accuracy (training dataset): 100.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation accuracy (training dataset): {qat_model.evaluate(normalized_train_dataset)[1]*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4feb68e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 176ms/step - loss: 11.7566 - accuracy: 0.0345\n",
      "Model evaluation accuracy (validation dataset): 3.448\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation accuracy (validation dataset): {qat_model.evaluate(valid_dataset)[1]*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "675d53fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 175ms/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Model evaluation accuracy (validation dataset): 99.517\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation accuracy (validation dataset): {qat_model.evaluate(normalized_valid_dataset)[1]*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb228f43",
   "metadata": {},
   "source": [
    "**Save quantized model**\n",
    "\n",
    "Once we are happy with the performance of the quantized model, we can save it as a .h5 file, simply using the `save` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7eb4a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantized_model.save('tf2_asl_classifier25_quantized.h5')\n",
    "qat_model.save('tf2_asl_classifier25_quantized.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58451641",
   "metadata": {},
   "source": [
    "## 5 Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974c603",
   "metadata": {},
   "source": [
    "For this final step we use the Vitis AI compiler `vai_c_tensorflow2` and pass the quantized model as a parameter. \n",
    "\n",
    "The target platform (ie. specific DPU architecture) is defined by .arch file.\n",
    "\n",
    "To support as many platforms as possible, we compile for the following DPU architectures:\n",
    "- B4096 (ZCU102, ZCU104, UltraZed-EV)\n",
    "- B3136 (KV260)\n",
    "- B2304 (Ultra96-V2)\n",
    "- B1152 (Ultra96-V2+DualCam)\n",
    "-  B512 (ZUBoard)\n",
    "-  B128 (ZUBoard+DualCam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ecf09d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./tf2_asl_classifier25_quantized.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/asl_classifier_DPUCZDX8G_ISA1_B4096_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/tf2_asl_classifier25_quantized.h5\n",
      "[INFO] keras version: 2.10.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 106/106 [00:00<00:00, 25899.81it/s]         \n",
      "[INFO] infer shape (NHWC)  :100%|█| 172/172 [00:00<00:00, 6614.77it/s]          \n",
      "[INFO] perform level-0 opt :100%|█| 1/1 [00:00<00:00, 69.53it/s]                \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 270.36it/s]               \n",
      "[INFO] infer shape (NHWC)  :100%|█| 174/174 [00:00<00:00, 6577.94it/s]          \n",
      "[INFO] generate xmodel     :100%|█| 174/174 [00:00<00:00, 2757.96it/s]          \n",
      "[INFO] dump xmodel: /tmp/asl_classifier_DPUCZDX8G_ISA1_B4096_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: null\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA1_B4096\n",
      "[UNILOG][INFO] Graph name: model, with op num: 384\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/./model_mobilenetv2/B4096/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/./model_mobilenetv2/B4096//asl_classifier.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is 625b8c0e4a5541f13e29b174cb73bcb5, and has been saved to \"/workspace/./model_mobilenetv2/B4096/md5sum.txt\"\n",
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./tf2_asl_classifier25_quantized.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/asl_classifier_DPUCZDX8G_ISA1_B3136_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/tf2_asl_classifier25_quantized.h5\n",
      "[INFO] keras version: 2.10.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 106/106 [00:00<00:00, 26100.52it/s]         \n",
      "[INFO] infer shape (NHWC)  :100%|█| 172/172 [00:00<00:00, 6772.56it/s]          \n",
      "[INFO] perform level-0 opt :100%|█| 1/1 [00:00<00:00, 68.45it/s]                \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 275.24it/s]               \n",
      "[INFO] infer shape (NHWC)  :100%|█| 174/174 [00:00<00:00, 6660.24it/s]          \n",
      "[INFO] generate xmodel     :100%|█| 174/174 [00:00<00:00, 2774.38it/s]          \n",
      "[INFO] dump xmodel: /tmp/asl_classifier_DPUCZDX8G_ISA1_B3136_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: null\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA1_B3136\n",
      "[UNILOG][INFO] Graph name: model, with op num: 384\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/./model_mobilenetv2/B3136/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/./model_mobilenetv2/B3136//asl_classifier.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is 418422883599b069f9a7726c1dda72b0, and has been saved to \"/workspace/./model_mobilenetv2/B3136/md5sum.txt\"\n",
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./tf2_asl_classifier25_quantized.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/asl_classifier_0x101000016010405_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/tf2_asl_classifier25_quantized.h5\n",
      "[INFO] keras version: 2.10.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 106/106 [00:00<00:00, 26351.13it/s]         \n",
      "[INFO] infer shape (NHWC)  :100%|█| 172/172 [00:00<00:00, 6832.67it/s]          \n",
      "[INFO] perform level-0 opt :100%|█| 1/1 [00:00<00:00, 68.71it/s]                \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 273.34it/s]               \n",
      "[INFO] infer shape (NHWC)  :100%|█| 174/174 [00:00<00:00, 6651.56it/s]          \n",
      "[INFO] generate xmodel     :100%|█| 174/174 [00:00<00:00, 2775.03it/s]          \n",
      "[INFO] dump xmodel: /tmp/asl_classifier_0x101000016010405_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: null\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA1_B2304_0101000016010405\n",
      "[UNILOG][INFO] Graph name: model, with op num: 384\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/./model_mobilenetv2/B2304/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/./model_mobilenetv2/B2304//asl_classifier.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is f840a17a31bf9cf6311fbe14b27185e9, and has been saved to \"/workspace/./model_mobilenetv2/B2304/md5sum.txt\"\n",
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./tf2_asl_classifier25_quantized.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/asl_classifier_0x101000017010203_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/tf2_asl_classifier25_quantized.h5\n",
      "[INFO] keras version: 2.10.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 106/106 [00:00<00:00, 26305.91it/s]         \n",
      "[INFO] infer shape (NHWC)  :100%|█| 172/172 [00:00<00:00, 6862.89it/s]          \n",
      "[INFO] perform level-0 opt :100%|█| 1/1 [00:00<00:00, 68.91it/s]                \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 275.15it/s]               \n",
      "[INFO] infer shape (NHWC)  :100%|█| 174/174 [00:00<00:00, 6673.88it/s]          \n",
      "[INFO] generate xmodel     :100%|█| 174/174 [00:00<00:00, 2773.27it/s]          \n",
      "[INFO] dump xmodel: /tmp/asl_classifier_0x101000017010203_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: null\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA1_B1152_0101000017010203\n",
      "[UNILOG][INFO] Graph name: model, with op num: 384\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/./model_mobilenetv2/B1152/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/./model_mobilenetv2/B1152//asl_classifier.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is 3fbc1ae030fc7cc87cb8754f363b7e2b, and has been saved to \"/workspace/./model_mobilenetv2/B1152/md5sum.txt\"\n",
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./tf2_asl_classifier25_quantized.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/asl_classifier_0x101000016010200_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/tf2_asl_classifier25_quantized.h5\n",
      "[INFO] keras version: 2.10.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 106/106 [00:00<00:00, 25975.47it/s]         \n",
      "[INFO] infer shape (NHWC)  :100%|█| 172/172 [00:00<00:00, 6698.05it/s]          \n",
      "[INFO] perform level-0 opt :100%|█| 1/1 [00:00<00:00, 68.43it/s]                \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 273.77it/s]               \n",
      "[INFO] infer shape (NHWC)  :100%|█| 174/174 [00:00<00:00, 6537.28it/s]          \n",
      "[INFO] generate xmodel     :100%|█| 174/174 [00:00<00:00, 2765.61it/s]          \n",
      "[INFO] dump xmodel: /tmp/asl_classifier_0x101000016010200_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: null\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA1_B512_0101000016010200\n",
      "[UNILOG][INFO] Graph name: model, with op num: 384\n",
      "[UNILOG][INFO] Begin to compile...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/./model_mobilenetv2/B512/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/./model_mobilenetv2/B512//asl_classifier.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is 70d4a43a51d384f2e4a2d050b4f1acb6, and has been saved to \"/workspace/./model_mobilenetv2/B512/md5sum.txt\"\n",
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./tf2_asl_classifier25_quantized.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/asl_classifier_0x101000002010208_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/tf2_asl_classifier25_quantized.h5\n",
      "[INFO] keras version: 2.10.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 106/106 [00:00<00:00, 26371.45it/s]         \n",
      "[INFO] infer shape (NHWC)  :100%|█| 172/172 [00:00<00:00, 6751.84it/s]          \n",
      "[INFO] perform level-0 opt :100%|█| 1/1 [00:00<00:00, 68.95it/s]                \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 277.53it/s]               \n",
      "[INFO] infer shape (NHWC)  :100%|█| 174/174 [00:00<00:00, 6653.38it/s]          \n",
      "[INFO] generate xmodel     :100%|█| 174/174 [00:00<00:00, 2780.32it/s]          \n",
      "[INFO] dump xmodel: /tmp/asl_classifier_0x101000002010208_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: null\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA1_B128_0101000002010208\n",
      "[UNILOG][INFO] Graph name: model, with op num: 384\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/./model_mobilenetv2/B128/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/./model_mobilenetv2/B128//asl_classifier.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is 4dc0e42b82ecb12a4ee639d38e05719e, and has been saved to \"/workspace/./model_mobilenetv2/B128/md5sum.txt\"\n"
     ]
    }
   ],
   "source": [
    "!vai_c_tensorflow2 \\\n",
    "    --model ./tf2_asl_classifier25_quantized.h5 \\\n",
    "    --arch ./arch/B4096/arch-zcu104.json \\\n",
    "    --output_dir ./model_mobilenetv2/B4096/ \\\n",
    "    --net_name asl_classifier\n",
    "\n",
    "!vai_c_tensorflow2 \\\n",
    "    --model ./tf2_asl_classifier25_quantized.h5 \\\n",
    "    --arch ./arch/B3136/arch-kv260.json \\\n",
    "    --output_dir ./model_mobilenetv2/B3136/ \\\n",
    "    --net_name asl_classifier\n",
    "\n",
    "!vai_c_tensorflow2 \\\n",
    "    --model ./tf2_asl_classifier25_quantized.h5 \\\n",
    "    --arch ./arch/B2304/arch-b2304-lr.json \\\n",
    "    --output_dir ./model_mobilenetv2/B2304/ \\\n",
    "    --net_name asl_classifier\n",
    "\n",
    "!vai_c_tensorflow2 \\\n",
    "    --model ./tf2_asl_classifier25_quantized.h5 \\\n",
    "    --arch ./arch/B1152/arch-b1152-hr.json \\\n",
    "    --output_dir ./model_mobilenetv2/B1152/ \\\n",
    "    --net_name asl_classifier\n",
    "\n",
    "!vai_c_tensorflow2 \\\n",
    "    --model ./tf2_asl_classifier25_quantized.h5 \\\n",
    "    --arch ./arch/B512/arch-b512-lr.json \\\n",
    "    --output_dir ./model_mobilenetv2/B512/ \\\n",
    "    --net_name asl_classifier\n",
    "\n",
    "!vai_c_tensorflow2 \\\n",
    "    --model ./tf2_asl_classifier25_quantized.h5 \\\n",
    "    --arch ./arch/B128/arch-b128-lr.json \\\n",
    "    --output_dir ./model_mobilenetv2/B128/ \\\n",
    "    --net_name asl_classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78e2b5",
   "metadata": {},
   "source": [
    "## 6 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3256950",
   "metadata": {},
   "source": [
    "In this notebook, we showed how to quantize and compile a TensorFlow2 model with Vitis-AI for deployment on AMD Zynq-UltraScale+ devices. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "c4_03_15a_ASL150_VGG_TransferLearn_FineTune_Conv2D_Train_Dense.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
